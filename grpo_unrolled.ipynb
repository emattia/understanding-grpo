{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from pprint import pprint\n",
    "import torch\n",
    "from torchtune import training, generation, rlhf\n",
    "from torchtune.modules import local_kv_cache\n",
    "from torchtune.dev.grpo.generation import generate\n",
    "from torchtune.dev.grpo.types import GRPOTrajectory\n",
    "from omegaconf import OmegaConf\n",
    "from IPython.display import HTML, Markdown\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from metaflow import Checkpoint, Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download checkpoint from Metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from metaflow import Checkpoint, Flow\n",
    "\n",
    "# with Checkpoint() as cp:\n",
    "#     run = Flow('TorchTuneFlow').latest_run\n",
    "#     latest = cp.list(task=run['flaky_count'].task)[0]\n",
    "#     cp.load(latest)\n",
    "#     with open(os.path.join(cp.directory, 'counter')) as f:\n",
    "#         print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# run = Flow('TorchTuneFlow').latest_run\n",
    "def download_latest(\n",
    "    model_dir=\"./trained_models\",\n",
    "    # s3_key='lora_adapter.tar.gz',\n",
    "    flow_name=\"TorchTuneFlow\",\n",
    "    artifact_name=\"model_ref\",\n",
    "    with_stats=True\n",
    "):\n",
    "    from metaflow import load_model, Flow\n",
    "    import os\n",
    "\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    latest_successful_run = Flow(flow_name).latest_successful_run\n",
    "    load_model(getattr(latest_successful_run.data, artifact_name), model_dir)\n",
    "    print(f\"Checkpoint downloaded and extracted to: {model_dir}\")\n",
    "    \n",
    "    if with_stats:\n",
    "        file_count = sum(len(files) for _, _, files in os.walk(model_dir))\n",
    "        dir_size = sum(os.path.getsize(os.path.join(root, file)) \n",
    "                    for root, _, files in os.walk(model_dir) \n",
    "                    for file in files)\n",
    "        dir_size_mb = dir_size / (1024 * 1024)\n",
    "        print(f\"Directory stats: {file_count} files, {dir_size_mb:.2f} MB total size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp = Checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "MetaflowS3NotFound",
     "evalue": "s3op failed:\nURL not found: s3://ob-nebius-test-bucket-1/metaflow-artifacts/mf.checkpoints/checkpoints/metadata/TorchTuneFlow/8977/train/67229-worker-2/\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/site-packages/metaflow/plugins/datatools/s3/s3.py:1640\u001b[0m, in \u001b[0;36mS3._s3op_with_retries.<locals>.try_s3_op\u001b[0;34m(last_ok_count, pending_retries, out_lines, inject_failures)\u001b[0m\n\u001b[1;32m   1639\u001b[0m env[\u001b[39m\"\u001b[39m\u001b[39mMETAFLOW_ESCAPE_HATCH_WARNING\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mFalse\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1640\u001b[0m stdout \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39;49mcheck_output(\n\u001b[1;32m   1641\u001b[0m     cmdline \u001b[39m+\u001b[39;49m addl_cmdline,\n\u001b[1;32m   1642\u001b[0m     cwd\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tmpdir,\n\u001b[1;32m   1643\u001b[0m     stderr\u001b[39m=\u001b[39;49mstderr\u001b[39m.\u001b[39;49mfile,\n\u001b[1;32m   1644\u001b[0m     env\u001b[39m=\u001b[39;49menv,\n\u001b[1;32m   1645\u001b[0m )\n\u001b[1;32m   1646\u001b[0m \u001b[39m# Here we did not have any error -- transient or otherwise.\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/subprocess.py:474\u001b[0m, in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39minput\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m empty\n\u001b[0;32m--> 474\u001b[0m \u001b[39mreturn\u001b[39;00m run(\u001b[39m*\u001b[39;49mpopenargs, stdout\u001b[39m=\u001b[39;49mPIPE, timeout\u001b[39m=\u001b[39;49mtimeout, check\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    475\u001b[0m            \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mstdout\n",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/subprocess.py:579\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[39mif\u001b[39;00m check \u001b[39mand\u001b[39;00m retcode:\n\u001b[0;32m--> 579\u001b[0m         \u001b[39mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[39m.\u001b[39margs,\n\u001b[1;32m    580\u001b[0m                                  output\u001b[39m=\u001b[39mstdout, stderr\u001b[39m=\u001b[39mstderr)\n\u001b[1;32m    581\u001b[0m \u001b[39mreturn\u001b[39;00m CompletedProcess(process\u001b[39m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['/home/eddie/micromamba/envs/dev/bin/python', '/home/eddie/micromamba/envs/dev/lib/python3.13/site-packages/metaflow/plugins/datatools/s3/s3op.py', 'list', '--inputs', '/home/eddie/dev/understanding-grpo/metaflow.s3.82x87q91/metaflow.s3.inputs.6h0t62lp']' returned non-zero exit status 6.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMetaflowS3NotFound\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/home/eddie/dev/understanding-grpo/grpo_unrolled.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnebius/home/eddie/dev/understanding-grpo/grpo_unrolled.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m Checkpoint() \u001b[39mas\u001b[39;00m cp:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bnebius/home/eddie/dev/understanding-grpo/grpo_unrolled.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     run \u001b[39m=\u001b[39m Flow(\u001b[39m'\u001b[39m\u001b[39mTorchTuneFlow\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mlatest_run\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bnebius/home/eddie/dev/understanding-grpo/grpo_unrolled.ipynb#Y133sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     latest \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39;49mlist(task\u001b[39m=\u001b[39;49mrun[\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtask)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/site-packages/metaflow_extensions/obcheckpoint/plugins/machine_learning_utilities/checkpoints/final_api.py:322\u001b[0m, in \u001b[0;36mCheckpoint.list\u001b[0;34m(self, name, task, attempt, full_namespace, as_dict)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39mif\u001b[39;00m _task_object \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[39m# If there is an explicit task object provided by the user\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[39m# Then we will list the checkpoints found in the task's latest attempt\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     _checkpointer \u001b[39m=\u001b[39m _instantiate_checkpointer_for_list(_task_object)\n\u001b[1;32m    319\u001b[0m     \u001b[39mreturn\u001b[39;00m _sort_checkpoints_by_version(\n\u001b[1;32m    320\u001b[0m         [\n\u001b[1;32m    321\u001b[0m             chckpt\u001b[39m.\u001b[39;49mto_dict() \u001b[39mif\u001b[39;49;00m as_dict \u001b[39melse\u001b[39;49;00m chckpt\n\u001b[0;32m--> 322\u001b[0m             \u001b[39mfor\u001b[39;49;00m chckpt \u001b[39min\u001b[39;49;00m _checkpointer\u001b[39m.\u001b[39;49m_list_checkpoints(\n\u001b[1;32m    323\u001b[0m                 name\u001b[39m=\u001b[39;49mname,\n\u001b[1;32m    324\u001b[0m                 attempt\u001b[39m=\u001b[39;49m_checkpointer\u001b[39m.\u001b[39;49m_attempt,\n\u001b[1;32m    325\u001b[0m                 within_task\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m full_namespace,\n\u001b[1;32m    326\u001b[0m             )\n\u001b[1;32m    327\u001b[0m         ]\n\u001b[1;32m    328\u001b[0m     )\n\u001b[1;32m    330\u001b[0m \u001b[39m# There is no task object clearly the user has called `Checkpoint.list`\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# within a Metaflow Task execution context (if it was not within task execution context\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# were not then we would have alreadyraised an exception). (outcome : (C1))\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m# Hence we will check if there is a checkpointer or we will safely instantiate\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m# a write checkpointer.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[39m# Outcome : (C3)\u001b[39;00m\n\u001b[1;32m    336\u001b[0m _checkpointer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpointer\n",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/site-packages/metaflow_extensions/obcheckpoint/plugins/machine_learning_utilities/checkpoints/checkpoint_storage.py:594\u001b[0m, in \u001b[0;36m_recover_checkpoints\u001b[0;34m(datastore, key_decomposer, name, attempt)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[39m# `datastore.list_paths` will have very different outputs based on the type of datastore.\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[39m# - for CheckpointMetadataStore it will list ALL checkpoints within the task.\u001b[39;00m\n\u001b[1;32m    587\u001b[0m \u001b[39m# - for CheckpointArtifactMetadataStore it will list ALL checkpoints within scope/the task-identifier.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39m# CheckpointArtifactStore it will list ALL checkpoints within the \"scope\"\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[39m# (this can be astoundingly large if things are running inside foreaches)\u001b[39;00m\n\u001b[0;32m--> 594\u001b[0m \u001b[39mfor\u001b[39;49;00m path_tup \u001b[39min\u001b[39;49;00m datastore\u001b[39m.\u001b[39;49mlist_paths([\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m]):\n\u001b[1;32m    595\u001b[0m     \u001b[39mtry\u001b[39;49;00m:\n\u001b[1;32m    596\u001b[0m         obj_info \u001b[39m=\u001b[39;49m key_decomposer(\n\u001b[1;32m    597\u001b[0m             path_tup\u001b[39m.\u001b[39;49mkey,\n\u001b[1;32m    598\u001b[0m         )\n",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/site-packages/metaflow_extensions/obcheckpoint/plugins/machine_learning_utilities/datastore/core.py:291\u001b[0m, in \u001b[0;36mObjectStorage.list_paths\u001b[0;34m(self, keys, recursive)\u001b[0m\n\u001b[1;32m    289\u001b[0m keys \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolve_key_path(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m keys]\n\u001b[1;32m    290\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m recursive:\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mfor\u001b[39;00m list_content_result \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mlist_content(keys):\n\u001b[1;32m    292\u001b[0m         \u001b[39myield\u001b[39;00m ListPathResult(\n\u001b[1;32m    293\u001b[0m             full_url\u001b[39m=\u001b[39m_full_url_convert(list_content_result\u001b[39m.\u001b[39mpath),\n\u001b[1;32m    294\u001b[0m             key\u001b[39m=\u001b[39m_relative_url_convert(list_content_result\u001b[39m.\u001b[39mpath),\n\u001b[1;32m    295\u001b[0m         )\n\u001b[1;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/site-packages/metaflow_extensions/obcheckpoint/plugins/datastores/s3_compat.py:151\u001b[0m, in \u001b[0;36mS3CompatibleStorage.list_content\u001b[0;34m(self, paths)\u001b[0m\n\u001b[1;32m    143\u001b[0m strip_prefix_len \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatastore_root\u001b[39m.\u001b[39mrstrip(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    144\u001b[0m \u001b[39mwith\u001b[39;00m S3(\n\u001b[1;32m    145\u001b[0m     s3root\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdatastore_root,\n\u001b[1;32m    146\u001b[0m     tmproot\u001b[39m=\u001b[39mARTIFACT_LOCALROOT,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     client_params\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_s3_client_params,\n\u001b[1;32m    150\u001b[0m ) \u001b[39mas\u001b[39;00m s3:\n\u001b[0;32m--> 151\u001b[0m     results \u001b[39m=\u001b[39m s3\u001b[39m.\u001b[39;49mlist_paths(paths)\n\u001b[1;32m    152\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    153\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlist_content_result(\n\u001b[1;32m    154\u001b[0m             path\u001b[39m=\u001b[39mo\u001b[39m.\u001b[39murl[strip_prefix_len:], is_file\u001b[39m=\u001b[39mo\u001b[39m.\u001b[39mexists\n\u001b[1;32m    155\u001b[0m         )\n\u001b[1;32m    156\u001b[0m         \u001b[39mfor\u001b[39;00m o \u001b[39min\u001b[39;00m results\n\u001b[1;32m    157\u001b[0m     ]\n",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/site-packages/metaflow/plugins/datatools/s3/s3.py:699\u001b[0m, in \u001b[0;36mS3.list_paths\u001b[0;34m(self, keys)\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m             \u001b[39myield\u001b[39;00m s3prefix, s3url, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(starmap(S3Object, _list(keys)))\n",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/site-packages/metaflow/plugins/datatools/s3/s3.py:693\u001b[0m, in \u001b[0;36mS3.list_paths.<locals>._list\u001b[0;34m(keys)\u001b[0m\n\u001b[1;32m    691\u001b[0m urls \u001b[39m=\u001b[39m ((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url(key)\u001b[39m.\u001b[39mrstrip(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m keys)\n\u001b[1;32m    692\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_read_many_files(\u001b[39m\"\u001b[39m\u001b[39mlist\u001b[39m\u001b[39m\"\u001b[39m, urls)\n\u001b[0;32m--> 693\u001b[0m \u001b[39mfor\u001b[39;49;00m s3prefix, s3url, size \u001b[39min\u001b[39;49;00m res:\n\u001b[1;32m    694\u001b[0m     \u001b[39mif\u001b[39;49;00m size:\n\u001b[1;32m    695\u001b[0m         \u001b[39myield\u001b[39;49;00m s3prefix, s3url, \u001b[39mNone\u001b[39;49;00m, \u001b[39mint\u001b[39;49m(size)\n",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/site-packages/metaflow/plugins/datatools/s3/s3.py:1419\u001b[0m, in \u001b[0;36mS3._read_many_files\u001b[0;34m(self, op, prefixes_and_ranges, **options)\u001b[0m\n\u001b[1;32m   1410\u001b[0m inputfile\u001b[39m.\u001b[39mwrite(\n\u001b[1;32m   1411\u001b[0m     \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m   1412\u001b[0m         [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1416\u001b[0m     )\n\u001b[1;32m   1417\u001b[0m )\n\u001b[1;32m   1418\u001b[0m inputfile\u001b[39m.\u001b[39mflush()\n\u001b[0;32m-> 1419\u001b[0m stdout_lines, stderr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_s3op_with_retries(\n\u001b[1;32m   1420\u001b[0m     op, inputs\u001b[39m=\u001b[39;49minputfile\u001b[39m.\u001b[39;49mname, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions\n\u001b[1;32m   1421\u001b[0m )\n\u001b[1;32m   1422\u001b[0m \u001b[39mif\u001b[39;00m stderr:\n\u001b[1;32m   1423\u001b[0m     \u001b[39mraise\u001b[39;00m MetaflowS3Exception(\n\u001b[1;32m   1424\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mGetting S3 files failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1425\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFirst prefix requested: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1426\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (prefixes_and_ranges[\u001b[39m0\u001b[39m], stderr)\n\u001b[1;32m   1427\u001b[0m     )\n",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/site-packages/metaflow/plugins/datatools/s3/s3.py:1721\u001b[0m, in \u001b[0;36mS3._s3op_with_retries\u001b[0;34m(self, mode, **options)\u001b[0m\n\u001b[1;32m   1713\u001b[0m                 \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, inject_failures, err_out\n\u001b[1;32m   1715\u001b[0m \u001b[39mwhile\u001b[39;00m retry_count \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m S3_RETRY_COUNT:\n\u001b[1;32m   1716\u001b[0m     (\n\u001b[1;32m   1717\u001b[0m         last_ok_count,\n\u001b[1;32m   1718\u001b[0m         last_retry_count,\n\u001b[1;32m   1719\u001b[0m         inject_failures,\n\u001b[1;32m   1720\u001b[0m         err_out,\n\u001b[0;32m-> 1721\u001b[0m     ) \u001b[39m=\u001b[39m try_s3_op(last_ok_count, pending_retries, out_lines, inject_failures)\n\u001b[1;32m   1722\u001b[0m     \u001b[39mif\u001b[39;00m err_out \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   1723\u001b[0m         last_retry_count \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1724\u001b[0m         \u001b[39mand\u001b[39;00m (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1731\u001b[0m         \u001b[39m# or we are out of transient retries\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m         \u001b[39m# so we will restart from scratch (being very conservative)\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m         retry_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/micromamba/envs/dev/lib/python3.13/site-packages/metaflow/plugins/datatools/s3/s3.py:1703\u001b[0m, in \u001b[0;36mS3._s3op_with_retries.<locals>.try_s3_op\u001b[0;34m(last_ok_count, pending_retries, out_lines, inject_failures)\u001b[0m\n\u001b[1;32m   1701\u001b[0m stderr\u001b[39m.\u001b[39mseek(\u001b[39m0\u001b[39m)\n\u001b[1;32m   1702\u001b[0m \u001b[39mif\u001b[39;00m ex\u001b[39m.\u001b[39mreturncode \u001b[39m==\u001b[39m s3op\u001b[39m.\u001b[39mERROR_URL_NOT_FOUND:\n\u001b[0;32m-> 1703\u001b[0m     \u001b[39mraise\u001b[39;00m MetaflowS3NotFound(err_out)\n\u001b[1;32m   1704\u001b[0m \u001b[39melif\u001b[39;00m ex\u001b[39m.\u001b[39mreturncode \u001b[39m==\u001b[39m s3op\u001b[39m.\u001b[39mERROR_URL_ACCESS_DENIED:\n\u001b[1;32m   1705\u001b[0m     \u001b[39mraise\u001b[39;00m MetaflowS3AccessDenied(err_out)\n",
      "\u001b[0;31mMetaflowS3NotFound\u001b[0m: s3op failed:\nURL not found: s3://ob-nebius-test-bucket-1/metaflow-artifacts/mf.checkpoints/checkpoints/metadata/TorchTuneFlow/8977/train/67229-worker-2/\n"
     ]
    }
   ],
   "source": [
    "# with Checkpoint() as cp:\n",
    "#     run = Flow('TorchTuneFlow').latest_run\n",
    "#     latest = cp.list(task=run['train'].task)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš¨ [Clone torchtune repo](https://github.com/pytorch/torchtune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchtune_path = '/home/eddie/dev/torchtune' # TODO: update to where you checked out the torchtune repo.\n",
    "# grpo_config = 'dev/3B_full_grpo.yaml'\n",
    "# sft_grpo_config = 'dev/3B_sft_for_grpo.yaml'\n",
    "# grpo_recipe = os.path.join(torchtune_path, 'recipes', 'dev/grpo_full_finetune_distributed.py')\n",
    "\n",
    "grpo_config = '/home/eddie/dev/nebius-experiments/projects/torchtune/multi_node_configs/70B_full_grpo.yaml'\n",
    "sft_grpo_config = None\n",
    "grpo_recipe = '/home/eddie/dev/nebius-experiments/projects/torchtune/multi_node_configs/70B_full_grpo.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook hack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to import torchtune recipe in REPL env like a notebook.\n",
    "\n",
    "import importlib.util\n",
    "module_name = \"grpo_recipe\"\n",
    "spec = importlib.util.spec_from_file_location(module_name, grpo_recipe)\n",
    "grpo_module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(grpo_module)\n",
    "FullGRPOFinetuneRecipeDistributed = grpo_module.FullGRPOFinetuneRecipeDistributed\n",
    "\n",
    "os.environ['RANK'] = '0'\n",
    "os.environ['WORLD_SIZE'] = '1'\n",
    "os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "os.environ['MASTER_PORT'] = '8001'\n",
    "# os.environ['WANDB_API_KEY'] = input('Paste WANDB key:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting manual seed to local seed 3928370272. Local seed is seed + rank = 3928370272 + 0\n"
     ]
    }
   ],
   "source": [
    "cfg = OmegaConf.load(os.path.join(torchtune_path, 'recipes/configs', grpo_config))\n",
    "recipe = FullGRPOFinetuneRecipeDistributed(cfg=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/eddie/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meddiem\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/eddie/dev/understanding-grpo/wandb/run-20250304_193624-dgn24cea</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eddiem/torchtune-test/runs/dgn24cea' target=\"_blank\">playful-sponge-7</a></strong> to <a href='https://wandb.ai/eddiem/torchtune-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eddiem/torchtune-test' target=\"_blank\">https://wandb.ai/eddiem/torchtune-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eddiem/torchtune-test/runs/dgn24cea' target=\"_blank\">https://wandb.ai/eddiem/torchtune-test/runs/dgn24cea</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FSDP is enabled. Instantiating model and loading checkpoint on Rank 0 ...\n",
      "Instantiating model and loading checkpoint took 2.19 secs\n",
      "Memory stats after model init:\n",
      "\tGPU peak memory active: 12.11 GiB\n",
      "\tGPU peak memory alloc: 12.11 GiB\n",
      "\tGPU peak memory reserved: 12.16 GiB\n",
      "Optimizer is initialized.\n",
      "Loss is initialized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f42553a3f74f60ad11c12cae3d0559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dataset and Sampler are initialized.\n",
      "Learning rate scheduler is initialized.\n",
      "`profile_memory` requires `with_stack` and `record_shapes`, these will be enabled since `profile_memory` is True\n",
      " Profiler config after instantiation: {'enabled': True, 'output_dir': '/tmp/checkpoints/grpo_llama3b/profiling_outputs', 'cpu': True, 'cuda': True, 'xpu': True, 'profile_memory': True, 'with_stack': True, 'record_shapes': True, 'with_flops': False, 'wait_steps': 5, 'warmup_steps': 3, 'active_steps': 2, 'num_cycles': 1}\n"
     ]
    }
   ],
   "source": [
    "recipe.setup(cfg=cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "self=recipe # trick this unrolled notebook into acting like the actual class\n",
    "training.cleanup_before_training()\n",
    "self._optimizer.zero_grad()\n",
    "grad_norm = None\n",
    "training_completed = False\n",
    "# self._profiler.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unroll a single epoch of the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_epoch=0\n",
    "self._sampler.set_epoch(curr_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What does a batch of data look like?\n",
    "\n",
    "The batch size is set in the config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A conversation between User and Assistant. The user asks a question, and the '\n",
      " 'Assistant solves it. The assistant first thinks about the reasoning process '\n",
      " 'in the mind and then provides the user with the answer. The reasoning '\n",
      " 'process and answer are enclosed within <think></think> and <answer></answer> '\n",
      " 'tags, respectively, i.e., <think>reasoning process here</think> '\n",
      " '<answer>answer here</answer>. User: Weng earns $12 an hour for babysitting. '\n",
      " 'Yesterday, she just did 50 minutes of babysitting. How much did she earn?. '\n",
      " 'Assistant: <think>\\n'\n",
      " '----------\\n'\n",
      " 'GROUND_TRUTH_ANSWER: '\n",
      " '10---------------------------------------------------------------------------------------- '\n",
      " 'A conversation between User and Assistant. The user asks a question, and the '\n",
      " 'Assistant solves it. The assistant first thinks about the reasoning process '\n",
      " 'in the mind and then provides the user with the answer. The reasoning '\n",
      " 'process and answer are enclosed within <think></think> and <answer></answer> '\n",
      " 'tags, respectively, i.e., <think>reasoning process here</think> '\n",
      " '<answer>answer here</answer>. User: Betty is saving money for a new wallet '\n",
      " 'which costs $100. Betty has only half of the money she needs. Her parents '\n",
      " 'decided to give her $15 for that purpose, and her grandparents twice as much '\n",
      " 'as her parents. How much more money does Betty need to buy the wallet?. '\n",
      " 'Assistant: <think>\\n'\n",
      " '----------\\n'\n",
      " 'GROUND_TRUTH_ANSWER: '\n",
      " '5---------------------------------------------------------------------------------------- '\n",
      " 'A conversation between User and Assistant. The user asks a question, and the '\n",
      " 'Assistant solves it. The assistant first thinks about the reasoning process '\n",
      " 'in the mind and then provides the user with the answer. The reasoning '\n",
      " 'process and answer are enclosed within <think></think> and <answer></answer> '\n",
      " 'tags, respectively, i.e., <think>reasoning process here</think> '\n",
      " '<answer>answer here</answer>. User: Julie is reading a 120-page book. '\n",
      " 'Yesterday, she was able to read 12 pages and today, she read twice as many '\n",
      " 'pages as yesterday. If she wants to read half of the remaining pages '\n",
      " 'tomorrow, how many pages should she read?. Assistant: <think>\\n'\n",
      " '----------\\n'\n",
      " 'GROUND_TRUTH_ANSWER: '\n",
      " '42---------------------------------------------------------------------------------------- '\n",
      " 'A conversation between User and Assistant. The user asks a question, and the '\n",
      " 'Assistant solves it. The assistant first thinks about the reasoning process '\n",
      " 'in the mind and then provides the user with the answer. The reasoning '\n",
      " 'process and answer are enclosed within <think></think> and <answer></answer> '\n",
      " 'tags, respectively, i.e., <think>reasoning process here</think> '\n",
      " '<answer>answer here</answer>. User: James writes a 3-page letter to 2 '\n",
      " 'different friends twice a week.  How many pages does he write a year?. '\n",
      " 'Assistant: <think>\\n'\n",
      " '----------\\n'\n",
      " 'GROUND_TRUTH_ANSWER: 624')\n"
     ]
    }
   ],
   "source": [
    "batch = next(self._dataloader._get_iterator())\n",
    "tokens = batch[\"tokens\"]         # tokenized prompts\n",
    "answers = batch[\"answers\"]       # untokenized answers\n",
    "tokens = tokens.to(self._device) # [batch_size x num_tokens_per_prompt]\n",
    "tokens_ls = tokens.tolist()\n",
    "out = []\n",
    "for i in range(tokens.shape[0]):\n",
    "    prompt = self._tokenizer.decode(tokens_ls[i])\n",
    "    answer = answers[i]\n",
    "    out.append(prompt+'\\n' + '-'*10+'\\n' + 'GROUND_TRUTH_ANSWER: ' + answer)\n",
    "sep = \"-\"*88+ ' '\n",
    "pprint(sep.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, context_length = tokens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a trajectory\n",
    "\n",
    "The main work within each iteration is to generate a \"trajectory\". \n",
    "These two functions drive the current codebase.\n",
    "\n",
    "```python\n",
    "def generate_trajectory_batched(\n",
    "        self, input_ids: torch.Tensor, answers: List[str]\n",
    "    ) -> GRPOTrajectory:\n",
    "        \"\"\"\n",
    "        Generates a ``self.batch_size`` batch of trajectories using `self._forward_batch_size` batch sizes.\n",
    "        See ``generate_trajectory`` for more details.\n",
    "\n",
    "        Args:\n",
    "            input_ids (torch.Tensor): tensor of input token IDs with shape [b, seq_length]\n",
    "            answers: (List[str]): list of answers corresponding to the input_ids\n",
    "\n",
    "        Returns:\n",
    "            Trajectory: An instance of :class:`~torchtune.rlhf.Trajectory`, comprising\n",
    "                the current trajectory.\n",
    "        \"\"\"\n",
    "```\n",
    "\n",
    "The work of this function happens in \n",
    "```python\n",
    "trajectories.append(\n",
    "    self.generate_trajectory(batch_input_ids, batch_answers)\n",
    ")\n",
    "```\n",
    "\n",
    "This function has the following signature:\n",
    "```python\n",
    "def generate_trajectory(\n",
    "    self, input_ids: torch.Tensor, answers: List[str]\n",
    ") -> GRPOTrajectory:\n",
    "    \"\"\"\n",
    "    Generates a trajectory given the current policy model, the reference policy model, the reward function,\n",
    "    and batch of inputs. This is done over the following steps:\n",
    "\n",
    "    1: Generate responses, and logits corresponding to the responses using the current policy,\n",
    "        generating (query, response) pairs.\n",
    "    2. Estimate logprobs of the generated responses using the current policy.\n",
    "    3. Compute rewards and successes for the generated responses.\n",
    "    4. Estimate advantages using GRPO.\n",
    "    5. Replace any tokens in the response after the first stop token (usually EOS token) with padding,\n",
    "        producing truncated responses.\n",
    "\n",
    "    Args:\n",
    "        input_ids (torch.Tensor): tensor of input token IDs with shape [b, seq_length]\n",
    "        answers (List[str]): list of answers corresponding to the input_ids\n",
    "\n",
    "    Returns:\n",
    "        Trajectory: An instance of :class:`~torchtune.rlhf.GRPOTrajectory` comprising\n",
    "            the current trajectory.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "This function contains the logic we want to step through to understand what drives learning in GRPO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_start = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trajectory = self.generate_trajectory_batched(tokens, answers)\n",
    "batch_input_ids = tokens[\n",
    "    batch_start : batch_start + self._forward_batch_size\n",
    "]\n",
    "batch_answers = answers[\n",
    "    batch_start : batch_start + self._forward_batch_size\n",
    "]\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of generate_trajectory\n",
    "\n",
    "batch_size, context_length = batch_input_ids.shape\n",
    "grpo_size = self.grpo_samples\n",
    "\n",
    "batch_input_ids = batch_input_ids[:, None, :].expand(-1, grpo_size, -1)  # [batch_size, grpo_size, L]\n",
    "batch_input_ids = batch_input_ids.reshape(batch_size * grpo_size, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_prompt(prompt, answer, tokenizer):\n",
    "    \"\"\"\n",
    "    Display prompt in HTML container for Jupyter and in cards of Metaflow tasks.\n",
    "\n",
    "    Args:\n",
    "        prompt: The tensor of prompt tokens\n",
    "        answer: A string with the answer to the prompt\n",
    "        tokenizer: The tokenizer to decode responses\n",
    "    \"\"\"\n",
    "    html_output = \"\"\"\n",
    "        <style>\n",
    "            .prompt-box {\n",
    "                margin: 20px 0;\n",
    "                padding: 15px;\n",
    "                border: 1px solid #C4C7AC;\n",
    "                border-radius: 8px;\n",
    "                background-color: #F0EBE5;\n",
    "                color: #4A4A67;\n",
    "                font-family: 'Courier New', monospace;\n",
    "                font-size: 14px;\n",
    "                line-height: 1.6;\n",
    "                white-space: pre-wrap;\n",
    "                word-wrap: break-word;\n",
    "            }\n",
    "        </style>\n",
    "    \"\"\"\n",
    "\n",
    "    ### PROCESS PROMPTS ###\n",
    "    if hasattr(prompt, 'shape'):\n",
    "        prompt_decoded = tokenizer.decode(\n",
    "            prompt[0].tolist() \n",
    "            if len(prompt.shape) > 0 and prompt.shape[0] > 0 else prompt.tolist()\n",
    "        )\n",
    "    else:\n",
    "        prompt_decoded = str(prompt)\n",
    "\n",
    "    ### SHOW PROMPT ###\n",
    "    formatted_prompt = prompt_decoded.replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n",
    "    formatted_prompt = formatted_prompt.replace(\"\\n\", \"<br>\")\n",
    "\n",
    "    html_output += '<div class=\"prompt-box\">'\n",
    "    html_output += f'<div style=\"background-color: #F0EBE5; font-size: 16px; font-weight: bold;\">Prompt</div>{formatted_prompt}'\n",
    "    html_output += \"<br>\"\n",
    "    html_output += f\"<strong>Ground Truth Answer: {answer}</strong>\"\n",
    "    html_output += '</div>'\n",
    "\n",
    "    return html_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .prompt-box {\n",
       "                margin: 20px 0;\n",
       "                padding: 15px;\n",
       "                border: 1px solid #C4C7AC;\n",
       "                border-radius: 8px;\n",
       "                background-color: #F0EBE5;\n",
       "                color: #4A4A67;\n",
       "                font-family: 'Courier New', monospace;\n",
       "                font-size: 14px;\n",
       "                line-height: 1.6;\n",
       "                white-space: pre-wrap;\n",
       "                word-wrap: break-word;\n",
       "            }\n",
       "        </style>\n",
       "    <div class=\"prompt-box\"><div style=\"background-color: #F0EBE5; font-size: 16px; font-weight: bold;\">Prompt</div>A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within &lt;think&gt;&lt;/think&gt; and &lt;answer&gt;&lt;/answer&gt; tags, respectively, i.e., &lt;think&gt;reasoning process here&lt;/think&gt; &lt;answer&gt;answer here&lt;/answer&gt;. User: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?. Assistant: &lt;think&gt;<br><strong>Ground Truth Answer: 5</strong></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(display_prompt(\n",
    "    prompt=batch_input_ids,\n",
    "    answer=batch_answers[0],\n",
    "    tokenizer=self._tokenizer\n",
    ")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Innermost generation\n",
    "\n",
    "At this point, we pass the tokenized batch of prompts into the core `generate` function.\n",
    "For GRPO, there is a custom version implemented, here is the signature:\n",
    "\n",
    "```python\n",
    "# NOTE: This is almost the same as torchtune.generation.generate, with a few changes necessary for GRPO.\n",
    "# Namely:\n",
    "#   1. The `return_logits` argument - we can optionally omit keeping track of logits during generation, which\n",
    "#        drastically improves generation speed.\n",
    "#   2. Stop token-based breaking now communicates across multiple devices in a distributed setting.\n",
    "# TODO: Figure out the right abstractions to be used in the main repository, and remove this function.\n",
    "@torch.no_grad()\n",
    "def generate(\n",
    "    model: TransformerDecoder,\n",
    "    prompt: torch.Tensor,\n",
    "    *,\n",
    "    max_generated_tokens: int,\n",
    "    pad_id: int = 0,\n",
    "    temperature: float = 1.0,\n",
    "    top_k: Optional[int] = None,\n",
    "    stop_tokens: Optional[List[int]] = None,\n",
    "    rng: Optional[torch.Generator] = None,\n",
    "    custom_generate_next_token: Optional[Callable] = None,\n",
    "    return_logits: bool = True,\n",
    ") -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea990cc6e3b842cf9b5cdb9199c2630e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/511 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with local_kv_cache(\n",
    "    model=self._model,\n",
    "    batch_size=batch_size * grpo_size,\n",
    "    device=self._device,\n",
    "    dtype=self._dtype,\n",
    "    decoder_max_seq_len=context_length + self._max_generated_tokens,\n",
    "):\n",
    "    query_responses, _ = generate(  # [B x G, L], [B x G, L, V]\n",
    "        model=self._model,\n",
    "        prompt=batch_input_ids,\n",
    "        max_generated_tokens=self._max_generated_tokens,\n",
    "        temperature=self._temperature,\n",
    "        top_k=self._top_k,\n",
    "        pad_id=self._tokenizer.pad_id,\n",
    "        rng=self._rng,\n",
    "        stop_tokens=self._tokenizer.stop_tokens,\n",
    "        return_logits=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert query_responses.shape[0] == grpo_size, 'The generate function is not making the correct number of GRPO samples.'\n",
    "assert query_responses.shape[1] <= self._max_generated_tokens, 'The generate function is not respecting max_generated_tokens.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.barrier()\n",
    "training._distributed.recursive_reshard(self._model)\n",
    "torch.cuda.empty_cache()\n",
    "responses = query_responses[:, context_length:].clone()\n",
    "query_response_padding_masks = query_responses != self._tokenizer.pad_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# solid color --> no padding tokens\n",
    "plt.imshow(query_response_padding_masks.cpu());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create attention masks and position IDs for any padding tokens in inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to mask the scores after the query-key multiplication and before the softmax. \n",
    "# This parameter is required during inference if caches have been setup.\n",
    "# A value of True in row ``i`` and column ``j`` means token ``i`` attends to token ``j``.\n",
    "masks = generation.get_causal_mask_from_padding_mask(\n",
    "    query_response_padding_masks\n",
    ")\n",
    "\n",
    "# Contains the position ids of each token. \n",
    "# This parameter is required during inference if caches have been setup.\n",
    "# During training, this is used to indicate the positions of each token relative to its sample.\n",
    "# During inference, this indicates the position of the current token.\n",
    "position_ids = generation.get_position_ids_from_padding_mask(\n",
    "    query_response_padding_masks\n",
    ")\n",
    "del query_response_padding_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perfect triangle means token at current step can only see tokens earlier in the autoregression sequence. \n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(masks[0].cpu());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the logits in a `forward` pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = self._model(query_responses, input_pos=position_ids, mask=masks)\n",
    "ref_logits = self._ref_model(query_responses, input_pos=position_ids, mask=masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert logits.shape[0] == grpo_size, 'The model forward pass is not making the correct number of GRPO samples.'\n",
    "assert logits.shape[1] <= self._max_generated_tokens, 'The model forward pass is not respecting max_generated_tokens.'\n",
    "assert logits.shape[2] == self._tokenizer.vocab_size - 1, 'The model forward pass is not respecting the vocab size.'\n",
    "\n",
    "assert ref_logits.shape[0] == grpo_size, 'The ref model forward pass is not making the correct number of GRPO samples.'\n",
    "assert ref_logits.shape[1] <= self._max_generated_tokens, 'The ref model forward pass is not respecting max_generated_tokens.'\n",
    "assert ref_logits.shape[2] == self._tokenizer.vocab_size - 1, 'The ref model forward pass is not respecting the vocab size.'\n",
    " \n",
    "assert logits.shape == ref_logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate logprobs of the response using the current and reference policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = logits[:, context_length - 1 :]\n",
    "logprobs = rlhf.batched_logits_to_logprobs(logits, responses, self._temperature)\n",
    "del logits\n",
    "torch.cuda.empty_cache()\n",
    "ref_logits = self._ref_model(\n",
    "    query_responses, input_pos=position_ids, mask=masks\n",
    ")\n",
    "ref_logits = rlhf.truncate_sequence_for_logprobs(ref_logits, context_length)\n",
    "ref_logprobs = rlhf.batched_logits_to_logprobs(\n",
    "    ref_logits, responses, self._temperature\n",
    ")\n",
    "del ref_logits\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert logprobs.shape == ref_logprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace any tokens in the responses after the first stop token (usually EOS token) with padding\n",
    "# resulting in truncated responses\n",
    "(\n",
    "    response_padding_masks,\n",
    "    responses,\n",
    ") = rlhf.truncate_sequence_at_first_stop_token(  # [B x G, L]\n",
    "    responses, self._stop_token_ids, self._tokenizer.pad_id\n",
    ")\n",
    "\n",
    "responses = responses.reshape(batch_size, grpo_size, -1)  # [B, G, L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8130d2d6d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOTE: compare to query_response_padding_masks above.\n",
    "plt.imshow(response_padding_masks.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Check how much money half of $100 is\n",
      "1/2 * 100 = <<1/2*100=50>>50\n",
      "Then Betty's grandfather can give her 100 - 50 = $<<100-50=50>>50\n",
      "Therefore, he need to get $50 to have money for the wallet\n",
      "Betty's parents need to give her ten times more than her grandparents giving them $50 x 10 = $<<50*10=500>>500\n",
      "So now check how much Betty needs to take for the wallet\n",
      "100 - 15 + 500 = $<<100-15+500=585>>585\n",
      "</think> <answer>585</answer>\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "for i in range(grpo_size):\n",
    "    decoded = self._tokenizer.decode(responses[:, i, :].tolist()[0])\n",
    "    print(decoded)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing rewards and successes\n",
    "\n",
    "Since the reward is obviously the interesting part here, lets implement it inline.\n",
    "Note that this is a signficant deviation from how rewards are being computed in the current `/dev` implementation.\n",
    "RL nerd-sniped me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Copied & slightly refactored from torchtune.dev.grpo.rewards import batch_shaped_correctness_reward.\n",
    "### Key changes\n",
    "# 1. Seperate reward function definition from reward batch processing logic.\n",
    "# 2. Slightly modified XML tag parsing.\n",
    "# 3. Reduce potential for false negative from formatting differences.\n",
    "# 4. Explicitly reward step-by-step reasoning.\n",
    "# 5. Option to return rewards with breakdown by component.\n",
    "\n",
    "from xml.etree import ElementTree as ET\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Union, Any\n",
    "import re\n",
    "import torch\n",
    "from dataclasses import dataclass, field\n",
    "from torchtune.modules.transforms.tokenizers import ModelTokenizer\n",
    "\n",
    "\n",
    "def extract_tags(text: str) -> dict[str, list[str]]:\n",
    "    \"\"\"\n",
    "    Parse XML-like tags from text. Returns a dictionary with keys 'think' and 'answer'.\n",
    "    The values are lists of strings, with each string being the content of a tag.\n",
    "    \"\"\"\n",
    "    cleaned_text = text.replace(\"<<\", \"\").replace(\">>\", \"\")\n",
    "    cleaned_text = re.sub(r'<\\s*(\\/?)\\s*(think|answer)\\s*>', r'<\\1\\2>', cleaned_text)\n",
    "    xml_string = f\"<root>{cleaned_text}</root>\"\n",
    "\n",
    "    try:\n",
    "        root = ET.fromstring(xml_string)\n",
    "        return {\n",
    "            \"think\": [\n",
    "                elem.text if elem.text is not None else \"\" for elem in root.findall(\"think\")\n",
    "            ],\n",
    "            \"answer\": [\n",
    "                elem.text if elem.text is not None else \"\"\n",
    "                for elem in root.findall(\"answer\")\n",
    "            ],\n",
    "        }\n",
    "    except ET.ParseError:\n",
    "        # Fall back to regex-based extraction if XML parsing fails\n",
    "        think_tags = re.findall(r'<think>(.*?)</think>', cleaned_text, re.DOTALL)\n",
    "        answer_tags = re.findall(r'<answer>(.*?)</answer>', cleaned_text, re.DOTALL)\n",
    "        return {\n",
    "            \"think\": think_tags,\n",
    "            \"answer\": answer_tags\n",
    "        }\n",
    "\n",
    "def normalize_answer(answer: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize answer string to handle common variations.\n",
    "    - Remove currency symbols, commas, and extra whitespace\n",
    "    - Standardize number format\n",
    "    \"\"\"\n",
    "    # Remove currency symbols, commas in numbers, and normalize whitespace\n",
    "    normalized = re.sub(r'[\\$,\\s]', '', answer)\n",
    "    \n",
    "    # Try to extract numbers if the answer is primarily numeric\n",
    "    number_match = re.search(r'[-+]?\\d*\\.?\\d+', normalized)\n",
    "    if number_match and len(number_match.group()) > len(normalized) * 0.5:\n",
    "        return number_match.group()\n",
    "    \n",
    "    return normalized.strip().lower()\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RewardComponentInfo:\n",
    "    \"\"\"Metadata for a reward component.\"\"\"\n",
    "    name: str\n",
    "    description: str\n",
    "    max_value: float\n",
    "    weight: float = 1.0\n",
    "    is_critical: bool = False\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RewardResult:\n",
    "    \"\"\"Result of evaluating a reward function.\"\"\"\n",
    "    raw_score: float\n",
    "    weighted_score: float\n",
    "    max_possible: float\n",
    "    is_fully_satisfied: bool = False\n",
    "    info: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "class RewardComponent:\n",
    "    \"\"\"Base class for reward components.\"\"\"\n",
    "\n",
    "    def __init__(self, info: RewardComponentInfo):\n",
    "        self.info = info \n",
    "    \n",
    "    def evaluate(self, context: Dict[str, Any], debug:bool=False) -> RewardResult:\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "class FormatComponent(RewardComponent):\n",
    "    \"\"\"Reward proper formatting with <think> and <answer> tags.\"\"\"\n",
    "\n",
    "    def evaluate(self, context: Dict[str, Any]) -> RewardResult:\n",
    "        tags = context['tags']\n",
    "        score = 0.0\n",
    "        info = {}\n",
    "        if len(tags[\"answer\"]) == 1: \n",
    "            answer_score = self.info.max_value / 2\n",
    "            info[\"answer_tag\"] = \"perfect\"\n",
    "        elif len(tags[\"answer\"]) > 1:\n",
    "            answer_score = self.info.max_value / 5 # some credit for having multiple <answer> tags.\n",
    "            info[\"answer_tag\"] = \"multiple\"\n",
    "        else:\n",
    "            answer_score = 0.0\n",
    "            info[\"answer_tag\"] = \"missing\"\n",
    "        if len(tags[\"think\"]) == 1:\n",
    "            think_score = self.info.max_value / 2\n",
    "            info[\"think_tag\"] = \"perfect\"\n",
    "        elif len(tags[\"think\"]) > 0:\n",
    "            think_score = self.info.max_value / 5\n",
    "            info[\"think_tag\"] = \"multiple\"\n",
    "        else:\n",
    "            think_score = 0.0\n",
    "            info[\"think_tag\"] = \"missing\"\n",
    "\n",
    "        score = answer_score + think_score\n",
    "        fully_satistifed = len(tags[\"answer\"]) == 1 and len(tags[\"think\"]) == 1\n",
    "\n",
    "        return RewardResult(\n",
    "            raw_score=score,\n",
    "            weighted_score=score * self.info.weight,\n",
    "            max_possible=self.info.max_value * self.info.weight,\n",
    "            is_fully_satisfied=fully_satistifed,\n",
    "            info=info\n",
    "        )\n",
    "    \n",
    "class ExactAnswerComponent(RewardComponent):\n",
    "    \"\"\"Reward component for exact answer match.\"\"\"\n",
    "    \n",
    "    def evaluate(self, context: Dict[str, Any]) -> RewardResult:\n",
    "        tags = context['tags']\n",
    "        normalized_ground_truth = context['normalized_ground_truth']\n",
    "        \n",
    "        normalized_answers = [normalize_answer(a) for a in tags[\"answer\"]]\n",
    "        \n",
    "        # Check for exact match\n",
    "        exact_match = normalized_ground_truth in normalized_answers\n",
    "        \n",
    "        score = self.info.max_value if exact_match else 0.0\n",
    "\n",
    "        info = {\n",
    "            \"exact_match\": exact_match,\n",
    "            \"normalized_answers\": normalized_answers,\n",
    "            \"normalized_ground_truth\": normalized_ground_truth\n",
    "        }\n",
    "        \n",
    "        return RewardResult(\n",
    "            raw_score=score,\n",
    "            weighted_score=score * self.info.weight,\n",
    "            max_possible=self.info.max_value * self.info.weight,\n",
    "            is_fully_satisfied=exact_match,\n",
    "            info=info\n",
    "        )\n",
    "\n",
    "\n",
    "class SubstringAnswerComponent(RewardComponent):\n",
    "    \"\"\"Reward component for substring match in answer.\"\"\"\n",
    "    \n",
    "    def evaluate(self, context: Dict[str, Any]) -> RewardResult:\n",
    "        tags = context['tags']\n",
    "        normalized_ground_truth = context['normalized_ground_truth']\n",
    "        \n",
    "        normalized_answers = [normalize_answer(a) for a in tags[\"answer\"]]\n",
    "        \n",
    "        # Check for substring match\n",
    "        substring_match = any(normalized_ground_truth in norm_ans for norm_ans in normalized_answers)\n",
    "        \n",
    "        score = self.info.max_value if substring_match else 0.0\n",
    "\n",
    "        info = {\n",
    "            \"substring_match\": substring_match,\n",
    "            \"normalized_answers\": normalized_answers,\n",
    "            \"normalized_ground_truth\": normalized_ground_truth\n",
    "        }\n",
    "        \n",
    "        return RewardResult(\n",
    "            raw_score=score,\n",
    "            weighted_score=score * self.info.weight,\n",
    "            max_possible=self.info.max_value * self.info.weight,\n",
    "            is_fully_satisfied=substring_match,\n",
    "            info=info\n",
    "        )\n",
    "\n",
    "\n",
    "class ReasoningQualityComponent(RewardComponent):\n",
    "    \"\"\"Reward component for evaluating quality of reasoning.\"\"\"\n",
    "    \n",
    "    def evaluate(self, context: Dict[str, Any]) -> RewardResult:\n",
    "        tags = context['tags']\n",
    "        answer = context['answer']\n",
    "        \n",
    "        if not tags[\"think\"]:\n",
    "            return RewardResult(\n",
    "                raw_score=0.0,\n",
    "                weighted_score=0.0,\n",
    "                max_possible=self.info.max_value * self.info.weight,\n",
    "                is_fully_satisfied=False,\n",
    "                info={\"reasoning\": \"missing\"}\n",
    "            )\n",
    "        \n",
    "        thinking = tags[\"think\"][0]\n",
    "        score = 0.0\n",
    "        info = {}\n",
    "        \n",
    "        # Reward for having calculation steps (numbers and operators)\n",
    "        calc_pattern = r'\\d+\\s*[\\+\\-\\*\\/]\\s*\\d+'\n",
    "        calculations = re.findall(calc_pattern, thinking)\n",
    "        calc_score = min(len(calculations), 5) * (self.info.max_value / 10)  # Up to half points for calculations\n",
    "        info[\"calculations\"] = len(calculations)\n",
    "        \n",
    "        # Check if final calculation leads to answer\n",
    "        normalized_answer = normalize_answer(answer)\n",
    "        answer_in_reasoning = normalized_answer in thinking\n",
    "        if answer_in_reasoning:\n",
    "            answer_score = 3.0 * (self.info.max_value / 10)  # 30% of max for answer in reasoning\n",
    "        else:\n",
    "            answer_score = 0.0\n",
    "        info[\"answer_in_reasoning\"] = answer_in_reasoning\n",
    "        \n",
    "        # Check for logical progression (consistent step-by-step approach)\n",
    "        step_pattern = re.search(r'(first|1st|step 1|begin|start).*?(then|next|2nd|step 2)', \n",
    "                              thinking, re.IGNORECASE|re.DOTALL)\n",
    "        if step_pattern:\n",
    "            step_score = 2.0 * (self.info.max_value / 10)  # 20% of max for step-by-step reasoning\n",
    "            info[\"step_reasoning\"] = True\n",
    "        else:\n",
    "            step_score = 0.0\n",
    "            info[\"step_reasoning\"] = False\n",
    "            \n",
    "        score = calc_score + answer_score + step_score\n",
    "        fully_satisfied = score >= self.info.max_value * 0.8\n",
    "        \n",
    "        return RewardResult(\n",
    "            raw_score=score,\n",
    "            weighted_score=score * self.info.weight,\n",
    "            max_possible=self.info.max_value * self.info.weight,\n",
    "            is_fully_satisfied=fully_satisfied,\n",
    "            info=info\n",
    "        )\n",
    "\n",
    "\n",
    "class CorrectFinalAnswerComponent(RewardComponent):\n",
    "    \"\"\"Critical component that gives full reward if final answer is correct.\"\"\"\n",
    "    \n",
    "    def evaluate(self, context: Dict[str, Any]) -> RewardResult:\n",
    "        tags = context['tags']\n",
    "        normalized_ground_truth = context['normalized_ground_truth']\n",
    "        \n",
    "        if not tags[\"answer\"]:\n",
    "            return RewardResult(\n",
    "                raw_score=0.0,\n",
    "                weighted_score=0.0,\n",
    "                max_possible=self.info.max_value * self.info.weight,\n",
    "                is_fully_satisfied=False,\n",
    "                info={\"final_answer\": \"missing\"}\n",
    "            )\n",
    "        \n",
    "        final_answer = normalize_answer(tags[\"answer\"][-1])\n",
    "        correct_final_answer = final_answer == normalized_ground_truth\n",
    "        \n",
    "        score = self.info.max_value if correct_final_answer else 0.0\n",
    "        info = {\n",
    "            \"correct_final_answer\": correct_final_answer,\n",
    "            \"final_answer\": final_answer,\n",
    "            \"normalized_ground_truth\": normalized_ground_truth\n",
    "        }\n",
    "        \n",
    "        return RewardResult(\n",
    "            raw_score=score,\n",
    "            weighted_score=score * self.info.weight,\n",
    "            max_possible=self.info.max_value * self.info.weight,\n",
    "            is_fully_satisfied=correct_final_answer,\n",
    "            info=info\n",
    "        )\n",
    "\n",
    "\n",
    "class RewardFunction:\n",
    "    \"\"\"\n",
    "    Aggregates multiple reward components and evaluates completions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, components: List[RewardComponent] = None):\n",
    "        self.components = components or []\n",
    "        self._setup_default_components()\n",
    "    \n",
    "    def _setup_default_components(self):\n",
    "        \"\"\"Set up the default reward components if none provided.\"\"\"\n",
    "        if not self.components:\n",
    "            self.components = [\n",
    "                FormatComponent(\n",
    "                    RewardComponentInfo(\n",
    "                        name=\"format\",\n",
    "                        description=\"Proper format with single think and answer tags\",\n",
    "                        max_value=10.0,\n",
    "                        weight=1.0\n",
    "                    )\n",
    "                ),\n",
    "                ExactAnswerComponent(\n",
    "                    RewardComponentInfo(\n",
    "                        name=\"exact_answer\",\n",
    "                        description=\"Exact match of answer in any answer tag\",\n",
    "                        max_value=20.0,\n",
    "                        weight=1.0\n",
    "                    )\n",
    "                ),\n",
    "                SubstringAnswerComponent(\n",
    "                    RewardComponentInfo(\n",
    "                        name=\"substring_answer\",\n",
    "                        description=\"Substring match of answer in any answer tag\",\n",
    "                        max_value=10.0,\n",
    "                        weight=1.0\n",
    "                    )\n",
    "                ),\n",
    "                ReasoningQualityComponent(\n",
    "                    RewardComponentInfo(\n",
    "                        name=\"reasoning\",\n",
    "                        description=\"Quality of reasoning in think tag\",\n",
    "                        max_value=10.0,\n",
    "                        weight=0.6\n",
    "                    )\n",
    "                ),\n",
    "                CorrectFinalAnswerComponent(\n",
    "                    RewardComponentInfo(\n",
    "                        name=\"correct_final_answer\",\n",
    "                        description=\"Correct answer in final answer tag\",\n",
    "                        max_value=100.0,\n",
    "                        weight=1.0,\n",
    "                        is_critical=True\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "    \n",
    "    def evaluate(\n",
    "        self, \n",
    "        answer: str, \n",
    "        completion: str,\n",
    "        return_details: bool = False\n",
    "    ) -> Union[Tuple[float, float], Tuple[float, float, Dict[str, Any]]]:\n",
    "        \"\"\"\n",
    "        Evaluate a completion against an answer.\n",
    "        \n",
    "        Args:\n",
    "            answer: The ground truth answer.\n",
    "            completion: The model's (decoded) completion.\n",
    "            return_details: Whether to return detailed component scores.\n",
    "            \n",
    "        Returns:\n",
    "            reward: Total reward value.\n",
    "            success: Binary success indicator (1.0 or 0.0).\n",
    "            details: (optional) Dictionary of component details.\n",
    "        \"\"\"\n",
    "        \n",
    "        tags = extract_tags(\"<think>\" + completion)\n",
    "        normalized_ground_truth = normalize_answer(answer)\n",
    "        \n",
    "        context = {\n",
    "            'answer': answer,\n",
    "            'completion': completion,\n",
    "            'tags': tags,\n",
    "            'normalized_ground_truth': normalized_ground_truth\n",
    "        }\n",
    "        \n",
    "        component_results = {}\n",
    "        total_reward = 0.0\n",
    "        success = 0.0\n",
    "        \n",
    "        for component in self.components:\n",
    "            result = component.evaluate(context)\n",
    "            component_results[component.info.name] = result\n",
    "            \n",
    "            total_reward += result.weighted_score\n",
    "            \n",
    "            if component.info.is_critical and result.is_fully_satisfied:\n",
    "                total_reward = 100.0  # Override with full reward\n",
    "                success = 1.0\n",
    "        \n",
    "        if return_details:\n",
    "            details = {\n",
    "                'component_results': component_results,\n",
    "                'total_reward': total_reward,\n",
    "                'success': success\n",
    "            }\n",
    "            return total_reward, success, details\n",
    "        \n",
    "        return total_reward, success\n",
    "\n",
    "\n",
    "def batch_shaped_correctness_reward(\n",
    "    tokenizer: ModelTokenizer, \n",
    "    completions: torch.Tensor, \n",
    "    answers: list[str],\n",
    "    reward_function: Optional[RewardFunction] = None,\n",
    "    return_details: bool = False\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Utility function to apply the shaped reward function to a GRPO-style batch of completions.\"\"\"\n",
    "\n",
    "    if reward_function is None:\n",
    "        reward_function = RewardFunction()\n",
    "\n",
    "    if return_details:\n",
    "        all_details = []\n",
    "\n",
    "    batch_size, grpo_size, *_ = completions.shape\n",
    "    rewards = torch.zeros(batch_size, grpo_size, dtype=torch.float32)\n",
    "    successes = torch.zeros(batch_size, grpo_size, dtype=torch.float32)\n",
    "    # completions :: [B, G, L]\n",
    "    for b in range(batch_size):\n",
    "        for g in range(grpo_size):\n",
    "            text_completion = tokenizer.decode(\n",
    "                completions[b, g].tolist()\n",
    "            )  # skips special tokens, stops at eos\n",
    "            if return_details:\n",
    "                reward, success, details = reward_function.evaluate(\n",
    "                    answer=answers[b],\n",
    "                    completion=text_completion,\n",
    "                    return_details=True\n",
    "                ) \n",
    "                all_details.append(details)\n",
    "            else:\n",
    "                reward, success = reward_function.evaluate(\n",
    "                    answer=answers[b],\n",
    "                    completion=text_completion\n",
    "                )\n",
    "            rewards[b, g] = reward\n",
    "            successes[b ,g] = success\n",
    "\n",
    "    if return_details:\n",
    "        return rewards, successes, all_details\n",
    "    \n",
    "    return rewards, successes, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use with default settings\n",
    "rewards, successes, details = batch_shaped_correctness_reward(\n",
    "    self._tokenizer, responses, answers, return_details=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100.0, 0.0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards[successes == 1].mean().item(), 0. if not rewards.shape[0] > 1 else rewards[successes == 1].std() \n",
    "# NOTE: 100, 0 for reward func above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing advantages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = rewards.to(self._device)\n",
    "successes = successes.to(self._device)\n",
    "\n",
    "advantages = (rewards - rewards.mean(1, keepdim=True)) / (\n",
    "    rewards.std(1, keepdim=True) + 1e-4\n",
    ")\n",
    "advantages = advantages.reshape(batch_size * grpo_size) # flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_responses(responses, tokenizer, grpo_size, advantages=None, rewards=None, successes=None, component_details=None, show_n:int=None):\n",
    "    \"\"\"\n",
    "    Display prompt in HTML container for Jupyter and in cards of Metaflow tasks.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The tensor of prompt tokens\n",
    "        responses: The tensor of response tokens\n",
    "        tokenizer: The tokenizer to decode responses\n",
    "        grpo_size: Number of responses to print\n",
    "        advantages: Optional tensor of advantage values [batch_size, grpo_size]. NOTE: current implementation assumes batch_size=1.\n",
    "        rewards: Optional tensor of reward values [batch_size, grpo_size]. NOTE: current implementation assumes batch_size=1.\n",
    "        successes: Optional tensor of success indicators [batch_size, grpo_size]\n",
    "        component_details: Optional list of component-level reward details\n",
    "    \n",
    "    Returns:\n",
    "        str that can be passed to IPython HTML display, embedded in Metaflow card or any other UI, of responses with optional reward metrics.\n",
    "    \"\"\"\n",
    "    import re\n",
    "\n",
    "    if rewards.shape[0] > 1:\n",
    "        raise Warning('Rewards dim 0 is > 1, meaning batch_size > 1. This function only displays the first member of the batch.')\n",
    "    \n",
    "    html_output = \"\"\"\n",
    "        <style>\n",
    "            .response-container {\n",
    "                margin: 20px 0;\n",
    "                border: 1px solid #C4C7AC;\n",
    "                border-radius: 8px;\n",
    "                overflow: hidden;\n",
    "                box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
    "                font-family: 'Courier New', monospace;\n",
    "                max-width: 100%;\n",
    "            }\n",
    "            .response-header {\n",
    "                background-color: #F0EBE5;\n",
    "                padding: 10px 15px;\n",
    "                font-size: 16px;\n",
    "                font-weight: bold;\n",
    "                border-bottom: 1px solid #C4C7AC;\n",
    "                color: #4A4A67;\n",
    "                display: flex;\n",
    "                justify-content: space-between;\n",
    "                align-items: center;\n",
    "            }\n",
    "            .response-body {\n",
    "                background-color: #ffffff;\n",
    "                color: #4A4A67;\n",
    "                padding: 15px;\n",
    "                white-space: pre-wrap;\n",
    "                word-wrap: break-word;\n",
    "                line-height: 1.6;\n",
    "                font-size: 14px;\n",
    "            }\n",
    "            .think-tag {\n",
    "                color: #BE6A1A;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .answer-tag {\n",
    "                color: #2C6846;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .calculation {\n",
    "                color: #2E5CA7;\n",
    "                background-color: #E9F0FA;\n",
    "                padding: 2px 4px;\n",
    "                border-radius: 2px;\n",
    "            }\n",
    "            .math {\n",
    "                font-family: 'Courier New', monospace;\n",
    "                background-color: #F0EBE5;\n",
    "                padding: 0 3px;\n",
    "                border-radius: 3px;\n",
    "            }\n",
    "            .metric-label {\n",
    "                color: #4A4A67;\n",
    "            }\n",
    "            .metrics-container {\n",
    "                background-color: #F0EBE5;\n",
    "                border-top: 1px solid #C4C7AC;\n",
    "                padding: 10px 15px;\n",
    "            }\n",
    "            .metric-score {\n",
    "                font-family: monospace;\n",
    "                font-weight: bold;\n",
    "                padding: 2px 8px;\n",
    "                border-radius: 4px;\n",
    "                display: inline-block;\n",
    "                margin-right: 8px;\n",
    "            }\n",
    "            .score-high {\n",
    "                background-color: #D3EFE0;\n",
    "                color: #177350;\n",
    "            }\n",
    "            .score-medium {\n",
    "                background-color: #FCF1D6;\n",
    "                color: #BE6A1A;\n",
    "            }\n",
    "            .score-low {\n",
    "                background-color: #FAD9D8;\n",
    "                color: #C5393A;\n",
    "            }\n",
    "            .success-badge {\n",
    "                background-color: #177350;\n",
    "                color: white;\n",
    "                padding: 3px 8px;\n",
    "                border-radius: 4px;\n",
    "                font-size: 12px;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .failure-badge {\n",
    "                background-color: #4A4A67;\n",
    "                color: white;\n",
    "                padding: 3px 8px;\n",
    "                border-radius: 4px;\n",
    "                font-size: 12px;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .component-table {\n",
    "                width: 100%;\n",
    "                border-collapse: collapse;\n",
    "                margin-top: 10px;\n",
    "                font-size: 13px;\n",
    "            }\n",
    "            .component-table th {\n",
    "                background-color: #F0EBE5;\n",
    "                text-align: left;\n",
    "                padding: 6px 10px;\n",
    "                color: #4A4A67;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .component-table td {\n",
    "                border-top: 1px solid #C4C7AC;\n",
    "                padding: 6px 10px;\n",
    "                color: #4A4A67;\n",
    "            }\n",
    "            .component-progress {\n",
    "                height: 8px;\n",
    "                width: 100%;\n",
    "                background-color: #E5E7D9;\n",
    "                border-radius: 4px;\n",
    "                overflow: hidden;\n",
    "            }\n",
    "            .component-progress-bar {\n",
    "                height: 100%;\n",
    "                background-color: #6B9BD0;\n",
    "            }\n",
    "            .metrics-toggle {\n",
    "                cursor: pointer;\n",
    "                color: #3F7DC9;\n",
    "                text-decoration: underline;\n",
    "                font-size: 12px;\n",
    "                margin-top: 5px;\n",
    "                display: inline-block;\n",
    "                font-weight: bold;\n",
    "            }\n",
    "            .details-container {\n",
    "                display: none;\n",
    "                margin-top: 10px;\n",
    "                border-top: 1px solid #C4C7AC;\n",
    "                padding-top: 10px;\n",
    "            }\n",
    "    </style>\n",
    "    <script>\n",
    "    function toggleDetails(id) {\n",
    "        var details = document.getElementById('details-' + id);\n",
    "        if (details.style.display === 'none' || details.style.display === '') {\n",
    "            details.style.display = 'block';\n",
    "        } else {\n",
    "            details.style.display = 'none';\n",
    "        }\n",
    "    }\n",
    "    </script>\n",
    "    \"\"\"\n",
    "    \n",
    "    has_rewards = rewards is not None and successes is not None\n",
    "    has_details = component_details is not None\n",
    "    \n",
    "    ### PROCESS RESPONSES ###\n",
    "    responses_decoded = []\n",
    "    for i in range(grpo_size):\n",
    "        try:\n",
    "            decoded = tokenizer.decode(responses[:, i, :].tolist()[0])\n",
    "            responses_decoded.append(decoded)\n",
    "        except:\n",
    "            responses_decoded.append(\"Sample response\")\n",
    "    \n",
    "    if show_n:\n",
    "        responses_decoded = responses_decoded[:show_n]\n",
    "\n",
    "    for i, response in enumerate(responses_decoded):\n",
    "        html_output += f'<div class=\"response-container\">'\n",
    "        ### START HEADER ###\n",
    "        html_output += f'<div class=\"response-header\">'\n",
    "        html_output += f'<div>Response #{i+1}</div>'\n",
    "        if has_rewards:\n",
    "            reward = rewards[0][i].item()  # Assuming batch_size=1 for simplicity\n",
    "            success = successes[0][i].item()\n",
    "            if success > 0.5:\n",
    "                html_output += f'<div class=\"success-badge\">SUCCESS</div>'\n",
    "            else:\n",
    "                html_output += f'<div class=\"failure-badge\">FAIL</div>'\n",
    "        html_output += '</div>'\n",
    "        ### START RESPONSE BODY ### \n",
    "        html_output += f'<div class=\"response-body\">'\n",
    "        response = response.replace(\"\\n\", \"<br>\")\n",
    "        # Escape HTML tags but keep <br> tags.\n",
    "        response = response.replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\")\n",
    "        response = response.replace(\"&lt;br&gt;\", \"<br>\")\n",
    "        ### HIGHLIGHT THINK TAGS ###\n",
    "        response = re.sub(\n",
    "            r'&lt;/think&gt;', \n",
    "            '<span class=\"think-tag\">&lt;/think&gt;</span>', \n",
    "            response\n",
    "        )\n",
    "        response = re.sub(\n",
    "            r'&lt;think&gt;', \n",
    "            '<span class=\"think-tag\">&lt;think&gt;</span>', \n",
    "            response\n",
    "        )\n",
    "        ### HIGHLIGHT ANSWER TAG ###\n",
    "        response = re.sub(\n",
    "            r'&lt;/answer&gt;', \n",
    "            '<span class=\"answer-tag\">&lt;/answer&gt;</span>', \n",
    "            response\n",
    "        )\n",
    "        response = re.sub(\n",
    "            r'&lt;answer&gt;', \n",
    "            '<span class=\"answer-tag\">&lt;answer&gt;</span>', \n",
    "            response\n",
    "        )\n",
    "        # HIGHLIGHT CALCULATIONS with $<<...>>$ pattern ###\n",
    "        response = re.sub(\n",
    "            r'\\$&lt;&lt;(.+?)&gt;&gt;\\$', \n",
    "            r'<span class=\"calculation\">$&lt;&lt;\\1&gt;&gt;$</span>', \n",
    "            response\n",
    "        )\n",
    "        ### FORMAT MATH EXPRESSIONS ###\n",
    "        response = re.sub(\n",
    "            r'(\\d+[*/+-]\\d+(?:[*/+-]\\d+)*)', \n",
    "            r'<span class=\"math\">\\1</span>', \n",
    "            response\n",
    "        )\n",
    "        html_output += response\n",
    "        html_output += '</div>' \n",
    "        ### START METRICS ###\n",
    "        if has_rewards:\n",
    "            html_output += f'<div class=\"metrics-container\">'\n",
    "            reward = rewards[0][i].item()  # Assuming batch_size=1\n",
    "            advantage = advantages[i].item()\n",
    "            score_class = \"score-high\" if reward >= 80 else \"score-medium\" if reward >= 30 else \"score-low\"\n",
    "            html_output += f'<div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score {score_class}\">{reward:.1f}</span></div>'\n",
    "            html_output += f'<div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score {score_class}\">{advantage:.1f}</span></div>'\n",
    "            if has_details and i < len(component_details):\n",
    "                details = component_details[i]\n",
    "                html_output += f'<a class=\"metrics-toggle\" onclick=\"toggleDetails({i})\">Show component details</a>'\n",
    "                html_output += f'<div id=\"details-{i}\" class=\"details-container\">'\n",
    "                ### TABLE OF COMPONENTS ###\n",
    "                html_output += '<table class=\"component-table\">'\n",
    "                html_output += '<tr><th>Component</th><th>Score</th><th>Weight</th><th>Contribution</th></tr>'\n",
    "                for comp_name, result in details['component_results'].items():\n",
    "                    raw_score = result.raw_score\n",
    "                    weighted_score = result.weighted_score\n",
    "                    max_possible = result.max_possible\n",
    "                    is_satisfied = result.is_fully_satisfied\n",
    "                    # For progress bar.\n",
    "                    percentage = (weighted_score / max_possible) * 100 if max_possible > 0 else 0\n",
    "                    # Format row in table. Another SO to Claude.\n",
    "                    status_color = \"#2b8a3e\" if is_satisfied else \"#e67700\"\n",
    "                    html_output += f'<tr>'\n",
    "                    html_output += f'<td style=\"color: {status_color}; font-weight: {(\"bold\" if is_satisfied else \"normal\")}\">{comp_name}</td>'\n",
    "                    max_raw = max_possible/result.weighted_score*raw_score if raw_score > 0 and result.weighted_score > 0 else max_possible\n",
    "                    html_output += f'<td>{raw_score:.1f} / {max_raw:.1f}</td>'\n",
    "                    html_output += f'<td>{result.weighted_score/raw_score if raw_score > 0 else 0:.1f}x</td>'\n",
    "                    html_output += f'<td>'\n",
    "                    html_output += f'<div class=\"component-progress\">'\n",
    "                    html_output += f'<div class=\"component-progress-bar\" style=\"width: {min(percentage, 100)}%; background-color: {status_color if is_satisfied else \"#4dabf7\"};\"></div>'\n",
    "                    html_output += f'</div>'\n",
    "                    html_output += f'</td>'\n",
    "                    html_output += f'</tr>'\n",
    "                html_output += '</table>'\n",
    "                # Show component by component \n",
    "                for comp_name, result in details['component_results'].items():\n",
    "                    if hasattr(result, 'debug_info') and result.debug_info:\n",
    "                        html_output += f'<div style=\"margin-top: 8px; font-size: 12px; color: #495057;\">'\n",
    "                        html_output += f'<strong>{comp_name} details:</strong> '            \n",
    "                        # Format debug info\n",
    "                        debug_parts = []\n",
    "                        for key, value in result.debug_info.items():\n",
    "                            if isinstance(value, bool):\n",
    "                                icon = \"âœ“\" if value else \"âœ—\"\n",
    "                                color = \"#2b8a3e\" if value else \"#c92a2a\"\n",
    "                                debug_parts.append(f'<span style=\"color: {color}\">{key}: {icon}</span>')\n",
    "                            else:\n",
    "                                debug_parts.append(f'{key}: {value}')\n",
    "                        html_output += ', '.join(debug_parts)\n",
    "                        html_output += '</div>'\n",
    "                html_output += '</div>'  # Close details container\n",
    "            html_output += '</div>'  # Close metrics container\n",
    "        html_output += '</div>'  # Close response container\n",
    "    \n",
    "    return html_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .prompt-box {\n",
       "                margin: 20px 0;\n",
       "                padding: 15px;\n",
       "                border: 1px solid #C4C7AC;\n",
       "                border-radius: 8px;\n",
       "                background-color: #F0EBE5;\n",
       "                color: #4A4A67;\n",
       "                font-family: 'Courier New', monospace;\n",
       "                font-size: 14px;\n",
       "                line-height: 1.6;\n",
       "                white-space: pre-wrap;\n",
       "                word-wrap: break-word;\n",
       "            }\n",
       "        </style>\n",
       "    <div class=\"prompt-box\"><div style=\"background-color: #F0EBE5; font-size: 16px; font-weight: bold;\">Prompt</div>A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within &lt;think&gt;&lt;/think&gt; and &lt;answer&gt;&lt;/answer&gt; tags, respectively, i.e., &lt;think&gt;reasoning process here&lt;/think&gt; &lt;answer&gt;answer here&lt;/answer&gt;. User: Betty is saving money for a new wallet which costs $100. Betty has only half of the money she needs. Her parents decided to give her $15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?. Assistant: &lt;think&gt;<br><strong>Ground Truth Answer: 5</strong></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <style>\n",
       "            .response-container {\n",
       "                margin: 20px 0;\n",
       "                border: 1px solid #C4C7AC;\n",
       "                border-radius: 8px;\n",
       "                overflow: hidden;\n",
       "                box-shadow: 0 2px 5px rgba(0,0,0,0.05);\n",
       "                font-family: 'Courier New', monospace;\n",
       "                max-width: 100%;\n",
       "            }\n",
       "            .response-header {\n",
       "                background-color: #F0EBE5;\n",
       "                padding: 10px 15px;\n",
       "                font-size: 16px;\n",
       "                font-weight: bold;\n",
       "                border-bottom: 1px solid #C4C7AC;\n",
       "                color: #4A4A67;\n",
       "                display: flex;\n",
       "                justify-content: space-between;\n",
       "                align-items: center;\n",
       "            }\n",
       "            .response-body {\n",
       "                background-color: #ffffff;\n",
       "                color: #4A4A67;\n",
       "                padding: 15px;\n",
       "                white-space: pre-wrap;\n",
       "                word-wrap: break-word;\n",
       "                line-height: 1.6;\n",
       "                font-size: 14px;\n",
       "            }\n",
       "            .think-tag {\n",
       "                color: #BE6A1A;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .answer-tag {\n",
       "                color: #2C6846;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .calculation {\n",
       "                color: #2E5CA7;\n",
       "                background-color: #E9F0FA;\n",
       "                padding: 2px 4px;\n",
       "                border-radius: 2px;\n",
       "            }\n",
       "            .math {\n",
       "                font-family: 'Courier New', monospace;\n",
       "                background-color: #F0EBE5;\n",
       "                padding: 0 3px;\n",
       "                border-radius: 3px;\n",
       "            }\n",
       "            .metric-label {\n",
       "                color: #4A4A67;\n",
       "            }\n",
       "            .metrics-container {\n",
       "                background-color: #F0EBE5;\n",
       "                border-top: 1px solid #C4C7AC;\n",
       "                padding: 10px 15px;\n",
       "            }\n",
       "            .metric-score {\n",
       "                font-family: monospace;\n",
       "                font-weight: bold;\n",
       "                padding: 2px 8px;\n",
       "                border-radius: 4px;\n",
       "                display: inline-block;\n",
       "                margin-right: 8px;\n",
       "            }\n",
       "            .score-high {\n",
       "                background-color: #D3EFE0;\n",
       "                color: #177350;\n",
       "            }\n",
       "            .score-medium {\n",
       "                background-color: #FCF1D6;\n",
       "                color: #BE6A1A;\n",
       "            }\n",
       "            .score-low {\n",
       "                background-color: #FAD9D8;\n",
       "                color: #C5393A;\n",
       "            }\n",
       "            .success-badge {\n",
       "                background-color: #177350;\n",
       "                color: white;\n",
       "                padding: 3px 8px;\n",
       "                border-radius: 4px;\n",
       "                font-size: 12px;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .failure-badge {\n",
       "                background-color: #4A4A67;\n",
       "                color: white;\n",
       "                padding: 3px 8px;\n",
       "                border-radius: 4px;\n",
       "                font-size: 12px;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .component-table {\n",
       "                width: 100%;\n",
       "                border-collapse: collapse;\n",
       "                margin-top: 10px;\n",
       "                font-size: 13px;\n",
       "            }\n",
       "            .component-table th {\n",
       "                background-color: #F0EBE5;\n",
       "                text-align: left;\n",
       "                padding: 6px 10px;\n",
       "                color: #4A4A67;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .component-table td {\n",
       "                border-top: 1px solid #C4C7AC;\n",
       "                padding: 6px 10px;\n",
       "                color: #4A4A67;\n",
       "            }\n",
       "            .component-progress {\n",
       "                height: 8px;\n",
       "                width: 100%;\n",
       "                background-color: #E5E7D9;\n",
       "                border-radius: 4px;\n",
       "                overflow: hidden;\n",
       "            }\n",
       "            .component-progress-bar {\n",
       "                height: 100%;\n",
       "                background-color: #6B9BD0;\n",
       "            }\n",
       "            .metrics-toggle {\n",
       "                cursor: pointer;\n",
       "                color: #3F7DC9;\n",
       "                text-decoration: underline;\n",
       "                font-size: 12px;\n",
       "                margin-top: 5px;\n",
       "                display: inline-block;\n",
       "                font-weight: bold;\n",
       "            }\n",
       "            .details-container {\n",
       "                display: none;\n",
       "                margin-top: 10px;\n",
       "                border-top: 1px solid #C4C7AC;\n",
       "                padding-top: 10px;\n",
       "            }\n",
       "    </style>\n",
       "    <script>\n",
       "    function toggleDetails(id) {\n",
       "        var details = document.getElementById('details-' + id);\n",
       "        if (details.style.display === 'none' || details.style.display === '') {\n",
       "            details.style.display = 'block';\n",
       "        } else {\n",
       "            details.style.display = 'none';\n",
       "        }\n",
       "    }\n",
       "    </script>\n",
       "    <div class=\"response-container\"><div class=\"response-header\"><div>Response #1</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\">Check how much money half of $100 is<br><span class=\"math\">1/2</span> * 100 = &lt;&lt;<span class=\"math\">1/2*100</span>=50&gt;&gt;50<br>Then Betty's grandfather can give her 100 - 50 = $&lt;&lt;<span class=\"math\">100-50</span>=50&gt;&gt;50<br>Therefore, he need to get $50 to have money for the wallet<br>Betty's parents need to give her ten times more than her grandparents giving them $50 x 10 = $&lt;&lt;<span class=\"math\">50*10</span>=500&gt;&gt;500<br>So now check how much Betty needs to take for the wallet<br>100 - 15 + 500 = $&lt;&lt;<span class=\"math\">100-15+500</span>=585&gt;&gt;585<br><span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-tag\">&lt;answer&gt;</span>585<span class=\"answer-tag\">&lt;/answer&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-low\">14.8</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-low\">-0.2</span></div><a class=\"metrics-toggle\" onclick=\"toggleDetails(0)\">Show component details</a><div id=\"details-0\" class=\"details-container\"><table class=\"component-table\"><tr><th>Component</th><th>Score</th><th>Weight</th><th>Contribution</th></tr><tr><td style=\"color: #2b8a3e; font-weight: bold\">format</td><td>10.0 / 10.0</td><td>1.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 100.0%; background-color: #2b8a3e;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">exact_answer</td><td>0.0 / 20.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">substring_answer</td><td>0.0 / 10.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr><tr><td style=\"color: #2b8a3e; font-weight: bold\">reasoning</td><td>8.0 / 10.0</td><td>0.6x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 80.0%; background-color: #2b8a3e;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">correct_final_answer</td><td>0.0 / 100.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr></table></div></div></div><div class=\"response-container\"><div class=\"response-header\"><div>Response #2</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\">Her parents gave her a $15 x 2 = $&lt;&lt;<span class=\"math\">15*2</span>=30&gt;&gt;30 discount<br>Betty might need to give $100 - $30 = $&lt;&lt;<span class=\"math\">100-30</span>=70&gt;&gt;70 more to buy the new wallet<br>She still has $150 - $70 = $&lt;&lt;<span class=\"math\">150-70</span>=80&gt;&gt;80 left without any discount<br>If she spends another $<span class=\"math\">80/2</span> = $&lt;&lt;<span class=\"math\">80/2</span>=40&gt;&gt;40 she has the money to buy the new wallet<br><span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-tag\">&lt;answer&gt;</span>40<span class=\"answer-tag\">&lt;/answer&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-low\">14.8</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-low\">-0.2</span></div><a class=\"metrics-toggle\" onclick=\"toggleDetails(1)\">Show component details</a><div id=\"details-1\" class=\"details-container\"><table class=\"component-table\"><tr><th>Component</th><th>Score</th><th>Weight</th><th>Contribution</th></tr><tr><td style=\"color: #2b8a3e; font-weight: bold\">format</td><td>10.0 / 10.0</td><td>1.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 100.0%; background-color: #2b8a3e;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">exact_answer</td><td>0.0 / 20.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">substring_answer</td><td>0.0 / 10.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr><tr><td style=\"color: #2b8a3e; font-weight: bold\">reasoning</td><td>8.0 / 10.0</td><td>0.6x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 80.0%; background-color: #2b8a3e;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">correct_final_answer</td><td>0.0 / 100.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr></table></div></div></div><div class=\"response-container\"><div class=\"response-header\"><div>Response #3</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\">Half of the money that beth needed to save is <span class=\"math\">100/2</span>=&lt;&lt;<span class=\"math\">100/2</span>=50&gt;&gt;50$.<br>Betty received <span class=\"math\">50+15</span> = $&lt;&lt;<span class=\"math\">50+15</span>=65&gt;&gt;65$ from her parents and grandparents.<br>Betty still needs <span class=\"math\">100-65</span> = $&lt;&lt;<span class=\"math\">100-65</span>=35&gt;&gt;35 $ to buy the wallet.<br><span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-tag\">&lt;answer&gt;</span>35<span class=\"answer-tag\">&lt;/answer&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-low\">14.8</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-low\">-0.2</span></div><a class=\"metrics-toggle\" onclick=\"toggleDetails(2)\">Show component details</a><div id=\"details-2\" class=\"details-container\"><table class=\"component-table\"><tr><th>Component</th><th>Score</th><th>Weight</th><th>Contribution</th></tr><tr><td style=\"color: #2b8a3e; font-weight: bold\">format</td><td>10.0 / 10.0</td><td>1.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 100.0%; background-color: #2b8a3e;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">exact_answer</td><td>0.0 / 20.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">substring_answer</td><td>0.0 / 10.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr><tr><td style=\"color: #2b8a3e; font-weight: bold\">reasoning</td><td>8.0 / 10.0</td><td>0.6x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 80.0%; background-color: #2b8a3e;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">correct_final_answer</td><td>0.0 / 100.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr></table></div></div></div><div class=\"response-container\"><div class=\"response-header\"><div>Response #4</div><div class=\"failure-badge\">FAIL</div></div><div class=\"response-body\">After her grandmotherÂ’s donation, Betty gains $15 + $15 = $&lt;&lt;<span class=\"math\">15+15</span>=30&gt;&gt;30 and has now $15 + $30 = $&lt;&lt;<span class=\"math\">15+30</span>=45&gt;&gt;45.<br>The amount of money BettyÂ’s parents donated is $45 - $15 = $30 for a total of $45 + $30 = $&lt;&lt;<span class=\"math\">45+30</span>=75&gt;&gt;75.<br>Betty still needs to save $100 - $45 - $30 = $&lt;&lt;<span class=\"math\">100-45-30</span>=25&gt;&gt;25 for the wallet.<br><span class=\"think-tag\">&lt;/think&gt;</span> <span class=\"answer-tag\">&lt;answer&gt;</span>25<span class=\"answer-tag\">&lt;/answer&gt;</span></div><div class=\"metrics-container\"><div><strong class=\"metric-label\">Reward:</strong> <span class=\"metric-score score-low\">14.2</span></div><div><strong class=\"metric-label\">Advantage:</strong> <span class=\"metric-score score-low\">-0.2</span></div><a class=\"metrics-toggle\" onclick=\"toggleDetails(3)\">Show component details</a><div id=\"details-3\" class=\"details-container\"><table class=\"component-table\"><tr><th>Component</th><th>Score</th><th>Weight</th><th>Contribution</th></tr><tr><td style=\"color: #2b8a3e; font-weight: bold\">format</td><td>10.0 / 10.0</td><td>1.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 100.0%; background-color: #2b8a3e;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">exact_answer</td><td>0.0 / 20.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">substring_answer</td><td>0.0 / 10.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">reasoning</td><td>7.0 / 10.0</td><td>0.6x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 70.0%; background-color: #4dabf7;\"></div></div></td></tr><tr><td style=\"color: #e67700; font-weight: normal\">correct_final_answer</td><td>0.0 / 100.0</td><td>0.0x</td><td><div class=\"component-progress\"><div class=\"component-progress-bar\" style=\"width: 0.0%; background-color: #4dabf7;\"></div></div></td></tr></table></div></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(display_prompt(\n",
    "    prompt=batch_input_ids,\n",
    "    answer=batch_answers[0],\n",
    "    tokenizer=self._tokenizer\n",
    ")))\n",
    "\n",
    "display(HTML(display_responses(\n",
    "    responses=responses,\n",
    "    tokenizer=self._tokenizer,\n",
    "    grpo_size=self.grpo_samples,\n",
    "    advantages=advantages,\n",
    "    rewards=rewards,\n",
    "    successes=successes,\n",
    "    component_details=details,\n",
    "    show_n=4\n",
    ")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "del responses\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "seq_lens = training.get_unmasked_sequence_lengths(response_padding_masks)\n",
    "\n",
    "### Mask out all the invalid values in the trajectory due to padding tokens\n",
    "logprobs[response_padding_masks] = 1.0\n",
    "ref_logprobs[response_padding_masks] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert logprobs.shape == ref_logprobs.shape, 'logprobs and reference model logprobs are not the same shape.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Single group')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x200 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(6,2))\n",
    "\n",
    "all_data = torch.concatenate([logprobs.detach().cpu().flatten(), \n",
    "                           ref_logprobs.detach().cpu().flatten()])\n",
    "vmin, vmax = torch.min(all_data), torch.max(all_data)\n",
    "norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Plot with the shared normalization\n",
    "im0 = ax[0].imshow(logprobs.detach().cpu(), norm=norm)\n",
    "ax[0].set_title('Current policy logprobs', size=10)\n",
    "\n",
    "im1 = ax[1].imshow(ref_logprobs.detach().cpu(), norm=norm)\n",
    "ax[1].set_title('Reference policy logprobs', size=10)\n",
    "\n",
    "# Set up axes\n",
    "for i in range(2):\n",
    "    ax[i].spines[[\"top\", \"bottom\", \"left\", \"right\"]].set_visible(False)\n",
    "    ax[i].set_xlabel(None)\n",
    "    ax[i].set_ylabel(None)\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "\n",
    "# Add a colorbar that applies to both subplots\n",
    "plt.tight_layout()\n",
    "fig.subplots_adjust(right=0.85)  # Make room for colorbar\n",
    "cbar_ax = fig.add_axes([0.87, 0.15, 0.03, 0.7])  # [left, bottom, width, height]\n",
    "cbar = fig.colorbar(im0, cax=cbar_ax)\n",
    "cbar.set_label('Log Probabilities', size=9)\n",
    "plt.title('Single group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = [\n",
    "    GRPOTrajectory(\n",
    "        query_responses=query_responses,\n",
    "        logprobs=logprobs,\n",
    "        ref_logprobs=ref_logprobs,\n",
    "        rewards=rewards.reshape(batch_size * grpo_size),\n",
    "        successes=successes.reshape(batch_size * grpo_size),\n",
    "        advantages=advantages,\n",
    "        masks=masks,\n",
    "        position_ids=position_ids,\n",
    "        response_padding_masks=response_padding_masks,\n",
    "        seq_lens=seq_lens,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = GRPOTrajectory(*map(torch.cat, zip(*trajectories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributed.barrier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "grpo_stats = []\n",
    "\n",
    "for _ in range(self._ppo_epochs):\n",
    "    # step_stats = self.grpo_step(trajectory, context_length)\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unrolling `self.grpo_step`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 436])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trajectory.query_responses.shape # [grpo_size, n_tokens_generated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('A conversation between User and Assistant. The user asks a question, and the '\n",
      " 'Assistant solves it. The assistant first thinks about the reasoning process '\n",
      " 'in the mind and then provides the user with the answer. The reasoning '\n",
      " 'process and answer are enclosed within <think></think> and <answer></answer> '\n",
      " 'tags, respectively, i.e., <think>reasoning process here</think> '\n",
      " '<answer>answer here</answer>. User: Betty is saving money for a new wallet '\n",
      " 'which costs $100. Betty has only half of the money she needs. Her parents '\n",
      " 'decided to give her $15 for that purpose, and her grandparents twice as much '\n",
      " 'as her parents. How much more money does Betty need to buy the wallet?. '\n",
      " 'Assistant: <think>For her to have $15*2=<<15*2=30>>30 from her grandparents, '\n",
      " 'she needs $100+30=<<100+30=130>>130\\n'\n",
      " '30 dollars more from her parents, and she needs to end up with in total '\n",
      " '$100+130=$230\\n'\n",
      " 'If she has $140 from her parents then she has 120+30=<<120+30=150>>150 with '\n",
      " 'her aunt Gracies.\\n'\n",
      " 'In total Betty needs $230-150=<<230-150=80>>80\\n'\n",
      " '</think> <answer>80</answer>')\n",
      "--------------------------------------------------------------------------------\n",
      "('For her to have $15*2=<<15*2=30>>30 from her grandparents, she needs '\n",
      " '$100+30=<<100+30=130>>130\\n'\n",
      " '30 dollars more from her parents, and she needs to end up with in total '\n",
      " '$100+130=$230\\n'\n",
      " 'If she has $140 from her parents then she has 120+30=<<120+30=150>>150 with '\n",
      " 'her aunt Gracies.\\n'\n",
      " 'In total Betty needs $230-150=<<230-150=80>>80\\n'\n",
      " '</think> <answer>80</answer>')\n"
     ]
    }
   ],
   "source": [
    "n = random.randint(0, trajectory.query_responses.shape[0]-1)\n",
    "pprint(self._tokenizer.decode(trajectory.query_responses[n].reshape(-1).tolist()))\n",
    "print('-'*80)\n",
    "pprint(self._tokenizer.decode(trajectory.query_responses[:, context_length:][n].reshape(-1).tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "pi_logits = self._model(\n",
    "    trajectory.query_responses,\n",
    "    input_pos=trajectory.position_ids,\n",
    "    mask=trajectory.masks,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_response_dim = pi_logits.shape[1] # pi_logits is tensor of shape [grpo_size, context_length + response_length, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_logits = rlhf.truncate_sequence_for_logprobs(pi_logits, context_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert prior_response_dim - context_length == pi_logits.shape[1], 'rlhf.truncate_sequence_for_logprobs is not producing right context window.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_logprobs = rlhf.batched_logits_to_logprobs(\n",
    "    pi_logits,\n",
    "    trajectory.query_responses[:, context_length:],\n",
    "    self._temperature,\n",
    "    chunk_size=1,\n",
    ") # The log probabilities corresponding to each token in the generated sequence part of trajectory.query_responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 288])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_logprobs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "del pi_logits\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtune import rlhf\n",
    "from torchtune.rlhf import masked_sum\n",
    "\n",
    "\n",
    "class GRPOLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Group Relative Policy Optimization (GRPO) Loss module.\n",
    "    Introduced by https://arxiv.org/abs/2402.03300, popularized by https://arxiv.org/abs/2501.12948.\n",
    "\n",
    "    This loss implementation follows the usual formulation of GRPO with clipped ratios of token-wise logprobs.\n",
    "    Currently not validated to perform well.\n",
    "\n",
    "    Args:\n",
    "        epsilon (float): clipping range for GRPO update.\n",
    "        kl_coeff (float): KL divergence coefficient (also known as beta).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        epsilon: float = 0.1,\n",
    "        kl_coeff: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.kl_coeff = kl_coeff\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pi_old_logprobs: torch.Tensor,  # [B x G, L]\n",
    "        pi_logprobs: torch.Tensor,  # [B x G, L]\n",
    "        ref_logprobs: torch.Tensor,  # [B x G, L]\n",
    "        advantages: torch.Tensor,  # [B x G]\n",
    "        padding_masks: Optional[torch.Tensor] = None,  # [B x G, L]\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass of the GRPO loss module.\n",
    "\n",
    "        Args:\n",
    "            pi_old_logprobs (torch.Tensor): Log probabilities of the old policy. Shape: [batch_size * num_groups, seq_len]\n",
    "            pi_logprobs (torch.Tensor): Log probabilities of the current policy. Shape: [batch_size * num_groups, seq_len]\n",
    "            ref_logprobs (torch.Tensor): Log probabilities of the reference model. Shape: [batch_size * num_groups, seq_len]\n",
    "            advantages (torch.Tensor): Advantage values. Shape: [batch_size * num_groups]\n",
    "            padding_masks (Optional[torch.Tensor]): Padding token masks where True indicates tokens to include in loss calculation.\n",
    "                Shape: [batch_size * num_groups, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]: A tuple containing:\n",
    "                - loss: Total GRPO loss (policy loss + KL penalty)\n",
    "                - policy_loss: Clipped policy loss\n",
    "                - kl_loss: KL divergence loss between policy and reference model\n",
    "                - ratios: Mean ratio between current and old policy probabilities\n",
    "                - clipfrac: Fraction of clipped policy ratios\n",
    "        \"\"\"\n",
    "\n",
    "        ratios = torch.exp(pi_logprobs - pi_old_logprobs)  # [B x G, L]\n",
    "        clipped_ratios = torch.clamp(\n",
    "            ratios, 1.0 - self.epsilon, 1.0 + self.epsilon\n",
    "        )  # [B x G, L]\n",
    "\n",
    "        advantages = advantages[:, None]  # [B x G, 1]\n",
    "\n",
    "        policy_losses_clipped = advantages * clipped_ratios  # [B x G, L]\n",
    "        policy_losses_unclipped = advantages * ratios  # [B x G, L]\n",
    "\n",
    "        clipfrac = (\n",
    "            policy_losses_clipped < policy_losses_unclipped\n",
    "        ).float()  # [B x G, L]\n",
    "        clipfrac = rlhf.masked_mean(clipfrac, padding_masks)  # scalar\n",
    "\n",
    "        policy_loss = torch.minimum(\n",
    "            policy_losses_clipped, policy_losses_unclipped\n",
    "        )  # [B x G, L]\n",
    "        policy_loss = rlhf.masked_mean(policy_loss, padding_masks)\n",
    "\n",
    "        kl_loss = (\n",
    "            torch.exp(ref_logprobs - pi_logprobs) - (ref_logprobs - pi_logprobs) - 1\n",
    "        )  # [B x G]\n",
    "        kl_loss = rlhf.masked_mean(kl_loss, padding_masks)\n",
    "\n",
    "        loss = -(policy_loss - self.kl_coeff * kl_loss)\n",
    "\n",
    "        return (\n",
    "            loss,\n",
    "            policy_loss.detach(),\n",
    "            kl_loss.detach(),\n",
    "            ratios.mean().detach(),\n",
    "            clipfrac.detach(),\n",
    "        )\n",
    "\n",
    "\n",
    "class GRPOCompletionLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Group Relative Policy Optimization (GRPO) Loss module.\n",
    "    Introduced by https://arxiv.org/abs/2402.03300, popularized by https://arxiv.org/abs/2501.12948.\n",
    "\n",
    "    This loss implementation follows the usual formulation of GRPO with clipped ratios of full completion logprobs.\n",
    "    Currently not validated to perform well.\n",
    "\n",
    "    Args:\n",
    "        epsilon (float): clipping range for GRPO update.\n",
    "        kl_coeff (float): KL divergence coefficient (also known as beta).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        epsilon: float = 0.1,\n",
    "        kl_coeff: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.kl_coeff = kl_coeff\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pi_old_logprobs: torch.Tensor,  # [B x G, L]\n",
    "        pi_logprobs: torch.Tensor,  # [B x G, L]\n",
    "        ref_logprobs: torch.Tensor,  # [B x G, L]\n",
    "        advantages: torch.Tensor,  # [B x G]\n",
    "        padding_masks: Optional[torch.Tensor] = None,  # [B x G, L]\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass of the GRPO loss module.\n",
    "\n",
    "        Args:\n",
    "            pi_old_logprobs (torch.Tensor): Log probabilities of the old policy. Shape: [batch_size * num_groups, seq_len]\n",
    "            pi_logprobs (torch.Tensor): Log probabilities of the current policy. Shape: [batch_size * num_groups, seq_len]\n",
    "            ref_logprobs (torch.Tensor): Log probabilities of the reference model. Shape: [batch_size * num_groups, seq_len]\n",
    "            advantages (torch.Tensor): Advantage values. Shape: [batch_size * num_groups]\n",
    "            padding_masks (Optional[torch.Tensor]): Padding token masks where True indicates tokens to include in loss calculation.\n",
    "                Shape: [batch_size * num_groups, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]: A tuple containing:\n",
    "                - loss: Total GRPO loss (policy loss + KL penalty)\n",
    "                - policy_loss: Clipped policy loss\n",
    "                - kl_loss: KL divergence loss between policy and reference model\n",
    "                - ratios: Mean ratio between current and old policy probabilities\n",
    "                - clipfrac: Fraction of clipped policy ratios\n",
    "        \"\"\"\n",
    "\n",
    "        pi_old_logprobs = masked_sum(pi_old_logprobs, padding_masks)  # [B x G]\n",
    "        pi_logprobs = masked_sum(pi_logprobs, padding_masks)  # [B x G]\n",
    "        ref_logprobs = masked_sum(ref_logprobs, padding_masks)  # [B x G]\n",
    "\n",
    "        ratios = torch.exp(pi_logprobs - pi_old_logprobs)  # [B x G]\n",
    "        clipped_ratios = torch.clamp(\n",
    "            ratios, 1.0 - self.epsilon, 1.0 + self.epsilon\n",
    "        )  # [B x G]\n",
    "\n",
    "        policy_losses_clipped = advantages * clipped_ratios  # [B x G]\n",
    "        policy_losses_unclipped = advantages * ratios  # [B x G]\n",
    "\n",
    "        clipfrac = (policy_losses_clipped < policy_losses_unclipped).float()  # [B x G]\n",
    "        clipfrac = clipfrac.mean()  # scalar, only for logging\n",
    "\n",
    "        policy_loss = torch.minimum(\n",
    "            policy_losses_clipped, policy_losses_unclipped\n",
    "        )  # [B x G]\n",
    "        policy_loss = policy_loss.mean()  # scalar\n",
    "\n",
    "        kl_loss = (\n",
    "            torch.exp(ref_logprobs - pi_logprobs) - (ref_logprobs - pi_logprobs) - 1\n",
    "        )  # [B x G]\n",
    "        kl_loss = rlhf.masked_mean(kl_loss, padding_masks)\n",
    "\n",
    "        loss = -(policy_loss - self.kl_coeff * kl_loss)\n",
    "\n",
    "        return (\n",
    "            loss,\n",
    "            policy_loss.detach(),\n",
    "            kl_loss.detach(),\n",
    "            ratios.mean().detach(),\n",
    "            clipfrac.detach(),\n",
    "        )\n",
    "\n",
    "\n",
    "class GRPOSimpleLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Group Relative Policy Optimization (GRPO) Loss module.\n",
    "    Introduced by https://arxiv.org/abs/2402.03300, popularized by https://arxiv.org/abs/2501.12948.\n",
    "\n",
    "    This loss implementation is based on TRL's implementation of GRPO,\n",
    "     which only takes a single gradient step per batch, trivializing some parts of the computation.\n",
    "     This empirically seems to perform well.\n",
    "\n",
    "    Args:\n",
    "        epsilon (float): clipping range for GRPO update.\n",
    "        kl_coeff (float): KL divergence coefficient (also known as beta).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        epsilon: float = 0.1,\n",
    "        kl_coeff: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.epsilon = epsilon\n",
    "        self.kl_coeff = kl_coeff\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pi_old_logprobs: torch.Tensor,  # [B x G, L]\n",
    "        pi_logprobs: torch.Tensor,  # [B x G, L]\n",
    "        ref_logprobs: torch.Tensor,  # [B x G, L]\n",
    "        advantages: torch.Tensor,  # [B x G]\n",
    "        padding_masks: Optional[torch.Tensor] = None,  # [B x G, L]\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward pass of the GRPO loss module.\n",
    "\n",
    "        Args:\n",
    "            pi_old_logprobs (torch.Tensor): *UNUSED* Log probabilities of the old policy.\n",
    "                Shape: [batch_size * num_groups, seq_len]\n",
    "            pi_logprobs (torch.Tensor): Log probabilities of the current policy.\n",
    "                Shape: [batch_size * num_groups, seq_len]\n",
    "            ref_logprobs (torch.Tensor): *UNUSED* Log probabilities of the reference model.\n",
    "                Shape: [batch_size * num_groups, seq_len]\n",
    "            advantages (torch.Tensor): Advantage values.\n",
    "                Shape: [batch_size * num_groups]\n",
    "            padding_masks (Optional[torch.Tensor]): Padding token masks where True indicates tokens to include in loss calculation.\n",
    "                Shape: [batch_size * num_groups, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]: A tuple containing:\n",
    "                - loss: Total GRPO loss (policy loss + KL penalty)\n",
    "                - policy_loss: Clipped policy loss\n",
    "                - kl_loss: KL divergence loss between policy and reference model\n",
    "                - ratios: Mean ratio between current and old policy probabilities\n",
    "                - clipfrac: Fraction of clipped policy ratios\n",
    "        \"\"\"\n",
    "\n",
    "        # [B x G, L]\n",
    "        per_token_kl = (\n",
    "            torch.exp(ref_logprobs.detach() - pi_logprobs)\n",
    "            - (ref_logprobs.detach() - pi_logprobs)\n",
    "            - 1\n",
    "        )\n",
    "\n",
    "        advantages = advantages[:, None]  # [B x G, 1]\n",
    "\n",
    "        per_token_policy_loss = (\n",
    "            torch.exp(pi_logprobs - pi_logprobs.detach()) * advantages\n",
    "        )\n",
    "\n",
    "        per_token_loss = -(per_token_policy_loss - self.kl_coeff * per_token_kl)\n",
    "\n",
    "        loss = rlhf.masked_mean(per_token_loss, padding_masks, dim=1).mean()\n",
    "\n",
    "        policy_loss = (\n",
    "            rlhf.masked_mean(per_token_policy_loss, padding_masks, dim=1)\n",
    "            .mean()\n",
    "            .detach()\n",
    "        )\n",
    "        kl_loss = rlhf.masked_mean(per_token_kl, padding_masks, dim=1).mean().detach()\n",
    "\n",
    "        return (  # This loss doesn't track clipfrac and ratios\n",
    "            loss,\n",
    "            policy_loss,\n",
    "            kl_loss,\n",
    "            torch.tensor(1.0),\n",
    "            torch.tensor(0.0),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = GRPOSimpleLoss(kl_coeff = 0.01, epsilon = 0.2)\n",
    "loss, policy_loss, kl_loss, ratios, clipfrac = loss_fn(\n",
    "    trajectory.logprobs,\n",
    "    pi_logprobs,\n",
    "    trajectory.ref_logprobs,\n",
    "    trajectory.advantages,\n",
    "    padding_masks=~trajectory.response_padding_masks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.),\n",
       " tensor(0.),\n",
       " tensor(0., device='cuda:0'),\n",
       " tensor(2.9802e-08, device='cuda:0'),\n",
       " tensor(-2.9802e-08, device='cuda:0', grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios, clipfrac, kl_loss, policy_loss, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
